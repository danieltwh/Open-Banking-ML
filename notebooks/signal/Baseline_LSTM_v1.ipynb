{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Baseline model. 1 layer LSTM with a classification layer trained for 100 epochs'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Baseline model. 1 layer LSTM with a classification layer trained for 100 epochs\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../../data/processed/signalEUR_USD_Labelled_v1_processed.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Date\"] = pd.to_datetime(df[\"Date\"])\n",
    "# Labels 3 days ahead\n",
    "df[\"label_3days\"] = df[\"label\"].shift(-3)\n",
    "# Labels 5 days ahead\n",
    "df[\"label_5days\"] = df[\"label\"].shift(-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Price</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Change %</th>\n",
       "      <th>diff_1</th>\n",
       "      <th>label</th>\n",
       "      <th>sma</th>\n",
       "      <th>ema</th>\n",
       "      <th>...</th>\n",
       "      <th>macd</th>\n",
       "      <th>macd_s</th>\n",
       "      <th>macd_h</th>\n",
       "      <th>roc</th>\n",
       "      <th>rsi</th>\n",
       "      <th>Bollinger_up</th>\n",
       "      <th>Bollinger_down</th>\n",
       "      <th>cci</th>\n",
       "      <th>label_3days</th>\n",
       "      <th>label_5days</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-02-15</td>\n",
       "      <td>1.3363</td>\n",
       "      <td>1.3363</td>\n",
       "      <td>1.3394</td>\n",
       "      <td>1.3306</td>\n",
       "      <td>0.01%</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.344735</td>\n",
       "      <td>1.336730</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002701</td>\n",
       "      <td>0.005461</td>\n",
       "      <td>-0.002760</td>\n",
       "      <td>-0.000150</td>\n",
       "      <td>39.939646</td>\n",
       "      <td>1.364281</td>\n",
       "      <td>1.325189</td>\n",
       "      <td>-62.849696</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-02-18</td>\n",
       "      <td>1.3352</td>\n",
       "      <td>1.3357</td>\n",
       "      <td>1.3377</td>\n",
       "      <td>1.3321</td>\n",
       "      <td>-0.08%</td>\n",
       "      <td>-0.0011</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.344925</td>\n",
       "      <td>1.335553</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001906</td>\n",
       "      <td>0.004750</td>\n",
       "      <td>-0.002844</td>\n",
       "      <td>-0.004102</td>\n",
       "      <td>38.588551</td>\n",
       "      <td>1.363994</td>\n",
       "      <td>1.325856</td>\n",
       "      <td>-68.561252</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-02-19</td>\n",
       "      <td>1.3388</td>\n",
       "      <td>1.3352</td>\n",
       "      <td>1.3397</td>\n",
       "      <td>1.3329</td>\n",
       "      <td>0.27%</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.345260</td>\n",
       "      <td>1.338051</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001549</td>\n",
       "      <td>0.004109</td>\n",
       "      <td>-0.002561</td>\n",
       "      <td>-0.004906</td>\n",
       "      <td>45.544851</td>\n",
       "      <td>1.363601</td>\n",
       "      <td>1.326919</td>\n",
       "      <td>-57.039491</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-02-20</td>\n",
       "      <td>1.3281</td>\n",
       "      <td>1.3387</td>\n",
       "      <td>1.3434</td>\n",
       "      <td>1.3270</td>\n",
       "      <td>-0.80%</td>\n",
       "      <td>-0.0107</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.345075</td>\n",
       "      <td>1.330396</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000398</td>\n",
       "      <td>0.003367</td>\n",
       "      <td>-0.002969</td>\n",
       "      <td>-0.012785</td>\n",
       "      <td>32.802173</td>\n",
       "      <td>1.364052</td>\n",
       "      <td>1.326098</td>\n",
       "      <td>-90.131403</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-02-21</td>\n",
       "      <td>1.3189</td>\n",
       "      <td>1.3283</td>\n",
       "      <td>1.3291</td>\n",
       "      <td>1.3161</td>\n",
       "      <td>-0.69%</td>\n",
       "      <td>-0.0092</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.344140</td>\n",
       "      <td>1.321553</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001242</td>\n",
       "      <td>0.002445</td>\n",
       "      <td>-0.003688</td>\n",
       "      <td>-0.012873</td>\n",
       "      <td>25.675429</td>\n",
       "      <td>1.366251</td>\n",
       "      <td>1.322029</td>\n",
       "      <td>-149.263447</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date   Price    Open    High     Low Change %  diff_1  label  \\\n",
       "0 2013-02-15  1.3363  1.3363  1.3394  1.3306    0.01%  0.0002    0.0   \n",
       "1 2013-02-18  1.3352  1.3357  1.3377  1.3321   -0.08% -0.0011    0.0   \n",
       "2 2013-02-19  1.3388  1.3352  1.3397  1.3329    0.27%  0.0036    2.0   \n",
       "3 2013-02-20  1.3281  1.3387  1.3434  1.3270   -0.80% -0.0107    1.0   \n",
       "4 2013-02-21  1.3189  1.3283  1.3291  1.3161   -0.69% -0.0092    1.0   \n",
       "\n",
       "        sma       ema  ...      macd    macd_s    macd_h       roc        rsi  \\\n",
       "0  1.344735  1.336730  ...  0.002701  0.005461 -0.002760 -0.000150  39.939646   \n",
       "1  1.344925  1.335553  ...  0.001906  0.004750 -0.002844 -0.004102  38.588551   \n",
       "2  1.345260  1.338051  ...  0.001549  0.004109 -0.002561 -0.004906  45.544851   \n",
       "3  1.345075  1.330396  ...  0.000398  0.003367 -0.002969 -0.012785  32.802173   \n",
       "4  1.344140  1.321553  ... -0.001242  0.002445 -0.003688 -0.012873  25.675429   \n",
       "\n",
       "   Bollinger_up  Bollinger_down         cci  label_3days  label_5days  \n",
       "0      1.364281        1.325189  -62.849696          1.0          0.0  \n",
       "1      1.363994        1.325856  -68.561252          1.0          1.0  \n",
       "2      1.363601        1.326919  -57.039491          0.0          0.0  \n",
       "3      1.364052        1.326098  -90.131403          1.0          2.0  \n",
       "4      1.366251        1.322029 -149.263447          0.0          1.0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.dropna(axis = 0)\n",
    "df = df.reset_index(drop=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = [\"Date\"]\n",
    "\n",
    "columns = [\"Price\",  \"sma\", \"ema\", \"cma\", \"macd\",\t\"macd_s\", \n",
    "           \"macd_h\", \"roc\", \"rsi\",\t\"Bollinger_up\", \"Bollinger_down\", \"cci\"]\n",
    "\n",
    "labels = [\"label\", \"label_3days\", \"label_5days\"]\n",
    "\n",
    "features = df[time + columns + labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Price</th>\n",
       "      <th>sma</th>\n",
       "      <th>ema</th>\n",
       "      <th>cma</th>\n",
       "      <th>macd</th>\n",
       "      <th>macd_s</th>\n",
       "      <th>macd_h</th>\n",
       "      <th>roc</th>\n",
       "      <th>rsi</th>\n",
       "      <th>Bollinger_up</th>\n",
       "      <th>Bollinger_down</th>\n",
       "      <th>cci</th>\n",
       "      <th>label</th>\n",
       "      <th>label_3days</th>\n",
       "      <th>label_5days</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-02-15</td>\n",
       "      <td>1.3363</td>\n",
       "      <td>1.344735</td>\n",
       "      <td>1.336730</td>\n",
       "      <td>1.335315</td>\n",
       "      <td>0.002701</td>\n",
       "      <td>0.005461</td>\n",
       "      <td>-0.002760</td>\n",
       "      <td>-0.000150</td>\n",
       "      <td>39.939646</td>\n",
       "      <td>1.364281</td>\n",
       "      <td>1.325189</td>\n",
       "      <td>-62.849696</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-02-18</td>\n",
       "      <td>1.3352</td>\n",
       "      <td>1.344925</td>\n",
       "      <td>1.335553</td>\n",
       "      <td>1.335311</td>\n",
       "      <td>0.001906</td>\n",
       "      <td>0.004750</td>\n",
       "      <td>-0.002844</td>\n",
       "      <td>-0.004102</td>\n",
       "      <td>38.588551</td>\n",
       "      <td>1.363994</td>\n",
       "      <td>1.325856</td>\n",
       "      <td>-68.561252</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-02-19</td>\n",
       "      <td>1.3388</td>\n",
       "      <td>1.345260</td>\n",
       "      <td>1.338051</td>\n",
       "      <td>1.335408</td>\n",
       "      <td>0.001549</td>\n",
       "      <td>0.004109</td>\n",
       "      <td>-0.002561</td>\n",
       "      <td>-0.004906</td>\n",
       "      <td>45.544851</td>\n",
       "      <td>1.363601</td>\n",
       "      <td>1.326919</td>\n",
       "      <td>-57.039491</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-02-20</td>\n",
       "      <td>1.3281</td>\n",
       "      <td>1.345075</td>\n",
       "      <td>1.330396</td>\n",
       "      <td>1.335211</td>\n",
       "      <td>0.000398</td>\n",
       "      <td>0.003367</td>\n",
       "      <td>-0.002969</td>\n",
       "      <td>-0.012785</td>\n",
       "      <td>32.802173</td>\n",
       "      <td>1.364052</td>\n",
       "      <td>1.326098</td>\n",
       "      <td>-90.131403</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-02-21</td>\n",
       "      <td>1.3189</td>\n",
       "      <td>1.344140</td>\n",
       "      <td>1.321553</td>\n",
       "      <td>1.334782</td>\n",
       "      <td>-0.001242</td>\n",
       "      <td>0.002445</td>\n",
       "      <td>-0.003688</td>\n",
       "      <td>-0.012873</td>\n",
       "      <td>25.675429</td>\n",
       "      <td>1.366251</td>\n",
       "      <td>1.322029</td>\n",
       "      <td>-149.263447</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date   Price       sma       ema       cma      macd    macd_s  \\\n",
       "0 2013-02-15  1.3363  1.344735  1.336730  1.335315  0.002701  0.005461   \n",
       "1 2013-02-18  1.3352  1.344925  1.335553  1.335311  0.001906  0.004750   \n",
       "2 2013-02-19  1.3388  1.345260  1.338051  1.335408  0.001549  0.004109   \n",
       "3 2013-02-20  1.3281  1.345075  1.330396  1.335211  0.000398  0.003367   \n",
       "4 2013-02-21  1.3189  1.344140  1.321553  1.334782 -0.001242  0.002445   \n",
       "\n",
       "     macd_h       roc        rsi  Bollinger_up  Bollinger_down         cci  \\\n",
       "0 -0.002760 -0.000150  39.939646      1.364281        1.325189  -62.849696   \n",
       "1 -0.002844 -0.004102  38.588551      1.363994        1.325856  -68.561252   \n",
       "2 -0.002561 -0.004906  45.544851      1.363601        1.326919  -57.039491   \n",
       "3 -0.002969 -0.012785  32.802173      1.364052        1.326098  -90.131403   \n",
       "4 -0.003688 -0.012873  25.675429      1.366251        1.322029 -149.263447   \n",
       "\n",
       "   label  label_3days  label_5days  \n",
       "0    0.0          1.0          0.0  \n",
       "1    0.0          1.0          1.0  \n",
       "2    2.0          0.0          0.0  \n",
       "3    1.0          1.0          2.0  \n",
       "4    1.0          0.0          1.0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "X = features.drop(labels= time + labels, axis=1)\n",
    "Y = features[[\"label\"]]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "onehot_encoder = OneHotEncoder()\n",
    "Y = to_categorical(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2311, 3)\n"
     ]
    }
   ],
   "source": [
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1848, 12) (463, 12)\n",
      "(1848, 3) (463, 3)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=420)\n",
    "print(X_train.shape, X_test.shape)\n",
    "print(Y_train.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_1 (LSTM)               (None, 100)               40800     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 3)                 303       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 41,103\n",
      "Trainable params: 41,103\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Input\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.losses import CategoricalCrossentropy\n",
    "\n",
    "h_dim = 100\n",
    "num_classes = 3\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=h_dim, input_shape=(X_train.shape[1], 1)))\n",
    "model.add(Dense(num_classes))\n",
    "model.compile(loss=CategoricalCrossentropy(from_logits=True), optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "29/29 [==============================] - 2s 19ms/step - loss: 1.0763 - accuracy: 0.4156 - val_loss: 1.0764 - val_accuracy: 0.4039\n",
      "Epoch 2/100\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 1.0496 - accuracy: 0.4551 - val_loss: 1.0660 - val_accuracy: 0.4147\n",
      "Epoch 3/100\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 1.0311 - accuracy: 0.4594 - val_loss: 1.0567 - val_accuracy: 0.4341\n",
      "Epoch 4/100\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 1.0129 - accuracy: 0.4643 - val_loss: 1.0418 - val_accuracy: 0.4838\n",
      "Epoch 5/100\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 1.0075 - accuracy: 0.4665 - val_loss: 1.0477 - val_accuracy: 0.4384\n",
      "Epoch 6/100\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 1.0051 - accuracy: 0.4729 - val_loss: 1.0446 - val_accuracy: 0.4687\n",
      "Epoch 7/100\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 1.0072 - accuracy: 0.4708 - val_loss: 1.0524 - val_accuracy: 0.4557\n",
      "Epoch 8/100\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 1.0009 - accuracy: 0.4805 - val_loss: 1.0389 - val_accuracy: 0.4428\n",
      "Epoch 9/100\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 1.0000 - accuracy: 0.4892 - val_loss: 1.0414 - val_accuracy: 0.4600\n",
      "Epoch 10/100\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.9942 - accuracy: 0.4903 - val_loss: 1.0449 - val_accuracy: 0.4557\n",
      "Epoch 11/100\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.9962 - accuracy: 0.4848 - val_loss: 1.0537 - val_accuracy: 0.4341\n",
      "Epoch 12/100\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.9909 - accuracy: 0.4794 - val_loss: 1.0376 - val_accuracy: 0.4557\n",
      "Epoch 13/100\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.9957 - accuracy: 0.4876 - val_loss: 1.0364 - val_accuracy: 0.4384\n",
      "Epoch 14/100\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.9881 - accuracy: 0.4957 - val_loss: 1.0334 - val_accuracy: 0.4514\n",
      "Epoch 15/100\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.9897 - accuracy: 0.4903 - val_loss: 1.0314 - val_accuracy: 0.4622\n",
      "Epoch 16/100\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.9917 - accuracy: 0.4951 - val_loss: 1.0377 - val_accuracy: 0.4536\n",
      "Epoch 17/100\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.9870 - accuracy: 0.5022 - val_loss: 1.0328 - val_accuracy: 0.4363\n",
      "Epoch 18/100\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.9859 - accuracy: 0.5022 - val_loss: 1.0340 - val_accuracy: 0.4406\n",
      "Epoch 19/100\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.9857 - accuracy: 0.5049 - val_loss: 1.0290 - val_accuracy: 0.4557\n",
      "Epoch 20/100\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.9822 - accuracy: 0.4989 - val_loss: 1.0187 - val_accuracy: 0.4622\n",
      "Epoch 21/100\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.9785 - accuracy: 0.5054 - val_loss: 1.0261 - val_accuracy: 0.4600\n",
      "Epoch 22/100\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.9762 - accuracy: 0.4989 - val_loss: 1.0179 - val_accuracy: 0.4536\n",
      "Epoch 23/100\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.9736 - accuracy: 0.5168 - val_loss: 1.0123 - val_accuracy: 0.4600\n",
      "Epoch 24/100\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.9746 - accuracy: 0.5173 - val_loss: 1.0185 - val_accuracy: 0.4622\n",
      "Epoch 25/100\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.9754 - accuracy: 0.5114 - val_loss: 1.0090 - val_accuracy: 0.4579\n",
      "Epoch 26/100\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.9795 - accuracy: 0.5081 - val_loss: 1.0070 - val_accuracy: 0.4752\n",
      "Epoch 27/100\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.9643 - accuracy: 0.5152 - val_loss: 1.0225 - val_accuracy: 0.4795\n",
      "Epoch 28/100\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.9655 - accuracy: 0.5173 - val_loss: 1.0043 - val_accuracy: 0.4773\n",
      "Epoch 29/100\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.9651 - accuracy: 0.5108 - val_loss: 0.9970 - val_accuracy: 0.4773\n",
      "Epoch 30/100\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.9524 - accuracy: 0.5211 - val_loss: 0.9838 - val_accuracy: 0.4838\n",
      "Epoch 31/100\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.9434 - accuracy: 0.5325 - val_loss: 0.9933 - val_accuracy: 0.4881\n",
      "Epoch 32/100\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.9394 - accuracy: 0.5308 - val_loss: 0.9563 - val_accuracy: 0.4816\n",
      "Epoch 33/100\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.9272 - accuracy: 0.5411 - val_loss: 0.9306 - val_accuracy: 0.5140\n",
      "Epoch 34/100\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.9223 - accuracy: 0.5557 - val_loss: 0.9440 - val_accuracy: 0.5313\n",
      "Epoch 35/100\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.9267 - accuracy: 0.5395 - val_loss: 0.9302 - val_accuracy: 0.5335\n",
      "Epoch 36/100\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.8983 - accuracy: 0.5487 - val_loss: 0.8980 - val_accuracy: 0.5508\n",
      "Epoch 37/100\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.8981 - accuracy: 0.5584 - val_loss: 0.8918 - val_accuracy: 0.5745\n",
      "Epoch 38/100\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.8946 - accuracy: 0.5633 - val_loss: 0.9116 - val_accuracy: 0.5529\n",
      "Epoch 39/100\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.8895 - accuracy: 0.5649 - val_loss: 0.8853 - val_accuracy: 0.5637\n",
      "Epoch 40/100\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.8808 - accuracy: 0.5660 - val_loss: 0.8947 - val_accuracy: 0.5443\n",
      "Epoch 41/100\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.8811 - accuracy: 0.5649 - val_loss: 0.9110 - val_accuracy: 0.5292\n",
      "Epoch 42/100\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.8714 - accuracy: 0.5833 - val_loss: 0.8651 - val_accuracy: 0.5702\n",
      "Epoch 43/100\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.8633 - accuracy: 0.5774 - val_loss: 0.8699 - val_accuracy: 0.5680\n",
      "Epoch 44/100\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.8641 - accuracy: 0.5752 - val_loss: 0.8531 - val_accuracy: 0.5724\n",
      "Epoch 45/100\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.8491 - accuracy: 0.5801 - val_loss: 0.8576 - val_accuracy: 0.5702\n",
      "Epoch 46/100\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.8501 - accuracy: 0.5920 - val_loss: 0.8476 - val_accuracy: 0.6048\n",
      "Epoch 47/100\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.8460 - accuracy: 0.5958 - val_loss: 0.8690 - val_accuracy: 0.5680\n",
      "Epoch 48/100\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.8485 - accuracy: 0.5985 - val_loss: 0.8543 - val_accuracy: 0.5680\n",
      "Epoch 49/100\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.8413 - accuracy: 0.5904 - val_loss: 0.8556 - val_accuracy: 0.5875\n",
      "Epoch 50/100\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.8399 - accuracy: 0.6017 - val_loss: 0.8530 - val_accuracy: 0.5875\n",
      "Epoch 51/100\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.8323 - accuracy: 0.6147 - val_loss: 0.8368 - val_accuracy: 0.5875\n",
      "Epoch 52/100\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.8427 - accuracy: 0.5947 - val_loss: 0.8530 - val_accuracy: 0.5572\n",
      "Epoch 53/100\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.8268 - accuracy: 0.6001 - val_loss: 0.8370 - val_accuracy: 0.5875\n",
      "Epoch 54/100\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.8217 - accuracy: 0.6082 - val_loss: 0.8603 - val_accuracy: 0.5594\n",
      "Epoch 55/100\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.8183 - accuracy: 0.6077 - val_loss: 0.8217 - val_accuracy: 0.6134\n",
      "Epoch 56/100\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.8221 - accuracy: 0.6088 - val_loss: 0.8201 - val_accuracy: 0.6134\n",
      "Epoch 57/100\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.8194 - accuracy: 0.6017 - val_loss: 0.8293 - val_accuracy: 0.6199\n",
      "Epoch 58/100\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.8132 - accuracy: 0.6098 - val_loss: 0.8270 - val_accuracy: 0.5853\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/100\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.8052 - accuracy: 0.6104 - val_loss: 0.8242 - val_accuracy: 0.6004\n",
      "Epoch 60/100\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.8075 - accuracy: 0.6190 - val_loss: 0.8437 - val_accuracy: 0.5896\n",
      "Epoch 61/100\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.7981 - accuracy: 0.6250 - val_loss: 0.8333 - val_accuracy: 0.5940\n",
      "Epoch 62/100\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.7949 - accuracy: 0.6212 - val_loss: 0.8286 - val_accuracy: 0.6048\n",
      "Epoch 63/100\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.7889 - accuracy: 0.6212 - val_loss: 0.8233 - val_accuracy: 0.6091\n",
      "Epoch 64/100\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.8032 - accuracy: 0.6109 - val_loss: 0.8993 - val_accuracy: 0.5443\n",
      "Epoch 65/100\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.7964 - accuracy: 0.6190 - val_loss: 0.8139 - val_accuracy: 0.6048\n",
      "Epoch 66/100\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.7963 - accuracy: 0.6131 - val_loss: 0.8234 - val_accuracy: 0.6026\n",
      "Epoch 67/100\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.7752 - accuracy: 0.6407 - val_loss: 0.8199 - val_accuracy: 0.6069\n",
      "Epoch 68/100\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.7807 - accuracy: 0.6288 - val_loss: 0.8101 - val_accuracy: 0.6199\n",
      "Epoch 69/100\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.7785 - accuracy: 0.6147 - val_loss: 0.8178 - val_accuracy: 0.6069\n",
      "Epoch 70/100\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.7725 - accuracy: 0.6234 - val_loss: 0.8092 - val_accuracy: 0.6112\n",
      "Epoch 71/100\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.7692 - accuracy: 0.6293 - val_loss: 0.8265 - val_accuracy: 0.5896\n",
      "Epoch 72/100\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.7821 - accuracy: 0.6277 - val_loss: 0.8194 - val_accuracy: 0.6263\n",
      "Epoch 73/100\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.7598 - accuracy: 0.6380 - val_loss: 0.8322 - val_accuracy: 0.6004\n",
      "Epoch 74/100\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.7610 - accuracy: 0.6272 - val_loss: 0.8323 - val_accuracy: 0.6026\n",
      "Epoch 75/100\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.7624 - accuracy: 0.6418 - val_loss: 0.8369 - val_accuracy: 0.5659\n",
      "Epoch 76/100\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.7573 - accuracy: 0.6402 - val_loss: 0.8093 - val_accuracy: 0.6004\n",
      "Epoch 77/100\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.7613 - accuracy: 0.6347 - val_loss: 0.8244 - val_accuracy: 0.5940\n",
      "Epoch 78/100\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.7559 - accuracy: 0.6299 - val_loss: 0.8167 - val_accuracy: 0.5961\n",
      "Epoch 79/100\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.7499 - accuracy: 0.6526 - val_loss: 0.8008 - val_accuracy: 0.6156\n",
      "Epoch 80/100\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.7470 - accuracy: 0.6564 - val_loss: 0.8120 - val_accuracy: 0.6112\n",
      "Epoch 81/100\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.7416 - accuracy: 0.6542 - val_loss: 0.8005 - val_accuracy: 0.6263\n",
      "Epoch 82/100\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.7379 - accuracy: 0.6499 - val_loss: 0.8202 - val_accuracy: 0.5940\n",
      "Epoch 83/100\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.7396 - accuracy: 0.6456 - val_loss: 0.8056 - val_accuracy: 0.6177\n",
      "Epoch 84/100\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.7322 - accuracy: 0.6580 - val_loss: 0.8083 - val_accuracy: 0.6091\n",
      "Epoch 85/100\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.7356 - accuracy: 0.6531 - val_loss: 0.8104 - val_accuracy: 0.6048\n",
      "Epoch 86/100\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.7333 - accuracy: 0.6537 - val_loss: 0.8073 - val_accuracy: 0.6285\n",
      "Epoch 87/100\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.7299 - accuracy: 0.6499 - val_loss: 0.8100 - val_accuracy: 0.6091\n",
      "Epoch 88/100\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.7306 - accuracy: 0.6526 - val_loss: 0.8413 - val_accuracy: 0.6199\n",
      "Epoch 89/100\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.7225 - accuracy: 0.6558 - val_loss: 0.8379 - val_accuracy: 0.6048\n",
      "Epoch 90/100\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.7275 - accuracy: 0.6553 - val_loss: 0.8070 - val_accuracy: 0.6199\n",
      "Epoch 91/100\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.7288 - accuracy: 0.6526 - val_loss: 0.8375 - val_accuracy: 0.6156\n",
      "Epoch 92/100\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.7195 - accuracy: 0.6569 - val_loss: 0.8174 - val_accuracy: 0.6069\n",
      "Epoch 93/100\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.7140 - accuracy: 0.6623 - val_loss: 0.8276 - val_accuracy: 0.6026\n",
      "Epoch 94/100\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.7138 - accuracy: 0.6694 - val_loss: 0.8311 - val_accuracy: 0.6026\n",
      "Epoch 95/100\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.7168 - accuracy: 0.6667 - val_loss: 0.8179 - val_accuracy: 0.6199\n",
      "Epoch 96/100\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.7028 - accuracy: 0.6683 - val_loss: 0.8104 - val_accuracy: 0.6004\n",
      "Epoch 97/100\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.7065 - accuracy: 0.6656 - val_loss: 0.8210 - val_accuracy: 0.6026\n",
      "Epoch 98/100\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.7073 - accuracy: 0.6656 - val_loss: 0.8251 - val_accuracy: 0.6048\n",
      "Epoch 99/100\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.6902 - accuracy: 0.6824 - val_loss: 0.8133 - val_accuracy: 0.6048\n",
      "Epoch 100/100\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.6954 - accuracy: 0.6688 - val_loss: 0.8355 - val_accuracy: 0.6048\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2a9141ca1f0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 100\n",
    "\n",
    "model.fit(X_train, Y_train, validation_data=(X_test, Y_test), epochs=epochs, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Without price as a factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.84392654,  1.76562961,  1.70005358, ...,  1.8683638 ,\n",
       "         1.80152324, -0.65041763],\n",
       "       [ 1.84605032,  1.75246368,  1.69999683, ...,  1.8651378 ,\n",
       "         1.80889088, -0.71655935],\n",
       "       [ 1.8497949 ,  1.78040628,  1.70167462, ...,  1.86074147,\n",
       "         1.82061006, -0.5831335 ],\n",
       "       ...,\n",
       "       [-0.56483883, -0.53162927, -0.96953338, ..., -0.69084061,\n",
       "        -0.43521197,  0.62254833],\n",
       "       [-0.55802035, -0.51948747, -0.96989049, ..., -0.69725765,\n",
       "        -0.41543563,  0.97031967],\n",
       "       [-0.55802035, -0.5261519 , -0.97025541, ..., -0.69725765,\n",
       "        -0.41543563,  0.92950638]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = features.drop(labels= time + labels + [\"Price\"], axis=1)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1848, 11) (463, 11)\n",
      "(1848, 3) (463, 3)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=420)\n",
    "print(X_train.shape, X_test.shape)\n",
    "print(Y_train.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_2 (LSTM)               (None, 100)               40800     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 3)                 303       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 41,103\n",
      "Trainable params: 41,103\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(units=h_dim, input_shape=(X_train.shape[1], 1)))\n",
    "model.add(Dense(num_classes))\n",
    "model.compile(loss=CategoricalCrossentropy(from_logits=True), optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "29/29 [==============================] - 2s 18ms/step - loss: 1.0756 - accuracy: 0.3896 - val_loss: 1.0765 - val_accuracy: 0.3996\n",
      "Epoch 2/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 1.0473 - accuracy: 0.4443 - val_loss: 1.0573 - val_accuracy: 0.4320\n",
      "Epoch 3/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 1.0238 - accuracy: 0.4740 - val_loss: 1.0522 - val_accuracy: 0.4536\n",
      "Epoch 4/100\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 1.0126 - accuracy: 0.4665 - val_loss: 1.0416 - val_accuracy: 0.4644\n",
      "Epoch 5/100\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 1.0064 - accuracy: 0.4773 - val_loss: 1.0516 - val_accuracy: 0.4644\n",
      "Epoch 6/100\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 1.0044 - accuracy: 0.4751 - val_loss: 1.0406 - val_accuracy: 0.4622\n",
      "Epoch 7/100\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.9992 - accuracy: 0.4854 - val_loss: 1.0460 - val_accuracy: 0.4428\n",
      "Epoch 8/100\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 1.0019 - accuracy: 0.4751 - val_loss: 1.0438 - val_accuracy: 0.4600\n",
      "Epoch 9/100\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.9968 - accuracy: 0.4870 - val_loss: 1.0408 - val_accuracy: 0.4514\n",
      "Epoch 10/100\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.9948 - accuracy: 0.4913 - val_loss: 1.0510 - val_accuracy: 0.4449\n",
      "Epoch 11/100\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.9954 - accuracy: 0.4886 - val_loss: 1.0429 - val_accuracy: 0.4363\n",
      "Epoch 12/100\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.9935 - accuracy: 0.4930 - val_loss: 1.0363 - val_accuracy: 0.4449\n",
      "Epoch 13/100\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.9936 - accuracy: 0.4968 - val_loss: 1.0312 - val_accuracy: 0.4600\n",
      "Epoch 14/100\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.9925 - accuracy: 0.5016 - val_loss: 1.0376 - val_accuracy: 0.4428\n",
      "Epoch 15/100\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.9907 - accuracy: 0.4892 - val_loss: 1.0318 - val_accuracy: 0.4384\n",
      "Epoch 16/100\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.9872 - accuracy: 0.4951 - val_loss: 1.0331 - val_accuracy: 0.4730\n",
      "Epoch 17/100\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.9872 - accuracy: 0.4908 - val_loss: 1.0262 - val_accuracy: 0.4600\n",
      "Epoch 18/100\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.9830 - accuracy: 0.5070 - val_loss: 1.0347 - val_accuracy: 0.4579\n",
      "Epoch 19/100\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.9823 - accuracy: 0.4940 - val_loss: 1.0248 - val_accuracy: 0.4752\n",
      "Epoch 20/100\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.9825 - accuracy: 0.5108 - val_loss: 1.0305 - val_accuracy: 0.4579\n",
      "Epoch 21/100\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.9832 - accuracy: 0.5022 - val_loss: 1.0322 - val_accuracy: 0.4665\n",
      "Epoch 22/100\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.9812 - accuracy: 0.5038 - val_loss: 1.0256 - val_accuracy: 0.4557\n",
      "Epoch 23/100\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.9771 - accuracy: 0.5065 - val_loss: 1.0171 - val_accuracy: 0.4622\n",
      "Epoch 24/100\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.9759 - accuracy: 0.5070 - val_loss: 1.0213 - val_accuracy: 0.4816\n",
      "Epoch 25/100\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.9738 - accuracy: 0.5097 - val_loss: 1.0119 - val_accuracy: 0.4730\n",
      "Epoch 26/100\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.9694 - accuracy: 0.5097 - val_loss: 1.0088 - val_accuracy: 0.4708\n",
      "Epoch 27/100\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.9725 - accuracy: 0.5130 - val_loss: 1.0105 - val_accuracy: 0.4622\n",
      "Epoch 28/100\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.9604 - accuracy: 0.5168 - val_loss: 1.0151 - val_accuracy: 0.4838\n",
      "Epoch 29/100\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.9604 - accuracy: 0.5308 - val_loss: 0.9958 - val_accuracy: 0.4752\n",
      "Epoch 30/100\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.9543 - accuracy: 0.5303 - val_loss: 0.9879 - val_accuracy: 0.4968\n",
      "Epoch 31/100\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.9549 - accuracy: 0.5195 - val_loss: 0.9819 - val_accuracy: 0.4795\n",
      "Epoch 32/100\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.9331 - accuracy: 0.5319 - val_loss: 0.9235 - val_accuracy: 0.5421\n",
      "Epoch 33/100\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.9251 - accuracy: 0.5482 - val_loss: 0.9747 - val_accuracy: 0.4903\n",
      "Epoch 34/100\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.9161 - accuracy: 0.5438 - val_loss: 0.9223 - val_accuracy: 0.5054\n",
      "Epoch 35/100\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.8978 - accuracy: 0.5460 - val_loss: 0.9050 - val_accuracy: 0.5356\n",
      "Epoch 36/100\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.8965 - accuracy: 0.5639 - val_loss: 0.8762 - val_accuracy: 0.5875\n",
      "Epoch 37/100\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.8813 - accuracy: 0.5617 - val_loss: 0.8764 - val_accuracy: 0.5745\n",
      "Epoch 38/100\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.8817 - accuracy: 0.5687 - val_loss: 0.8788 - val_accuracy: 0.5551\n",
      "Epoch 39/100\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.8652 - accuracy: 0.5682 - val_loss: 0.8720 - val_accuracy: 0.5680\n",
      "Epoch 40/100\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.8679 - accuracy: 0.5833 - val_loss: 0.8445 - val_accuracy: 0.6004\n",
      "Epoch 41/100\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.8573 - accuracy: 0.5839 - val_loss: 0.8685 - val_accuracy: 0.5464\n",
      "Epoch 42/100\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.8515 - accuracy: 0.5709 - val_loss: 0.8504 - val_accuracy: 0.5875\n",
      "Epoch 43/100\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.8576 - accuracy: 0.5915 - val_loss: 0.8493 - val_accuracy: 0.5853\n",
      "Epoch 44/100\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.8569 - accuracy: 0.5817 - val_loss: 0.8453 - val_accuracy: 0.5832\n",
      "Epoch 45/100\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.8336 - accuracy: 0.6006 - val_loss: 0.8767 - val_accuracy: 0.5508\n",
      "Epoch 46/100\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.8352 - accuracy: 0.5979 - val_loss: 0.8380 - val_accuracy: 0.5832\n",
      "Epoch 47/100\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.8287 - accuracy: 0.5915 - val_loss: 0.8276 - val_accuracy: 0.6004\n",
      "Epoch 48/100\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.8276 - accuracy: 0.6071 - val_loss: 0.8469 - val_accuracy: 0.5464\n",
      "Epoch 49/100\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.8245 - accuracy: 0.6093 - val_loss: 0.8286 - val_accuracy: 0.5983\n",
      "Epoch 50/100\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.8353 - accuracy: 0.5969 - val_loss: 0.8379 - val_accuracy: 0.5745\n",
      "Epoch 51/100\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.8226 - accuracy: 0.6012 - val_loss: 0.8208 - val_accuracy: 0.5983\n",
      "Epoch 52/100\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.8111 - accuracy: 0.6212 - val_loss: 0.8496 - val_accuracy: 0.5659\n",
      "Epoch 53/100\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.8018 - accuracy: 0.6169 - val_loss: 0.8232 - val_accuracy: 0.6048\n",
      "Epoch 54/100\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.8127 - accuracy: 0.6115 - val_loss: 0.8202 - val_accuracy: 0.6177\n",
      "Epoch 55/100\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.8138 - accuracy: 0.6082 - val_loss: 0.8185 - val_accuracy: 0.6069\n",
      "Epoch 56/100\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.7899 - accuracy: 0.6207 - val_loss: 0.8248 - val_accuracy: 0.6026\n",
      "Epoch 57/100\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.8055 - accuracy: 0.6223 - val_loss: 0.8544 - val_accuracy: 0.5724\n",
      "Epoch 58/100\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.7892 - accuracy: 0.6245 - val_loss: 0.8365 - val_accuracy: 0.5680\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/100\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.7917 - accuracy: 0.6239 - val_loss: 0.8371 - val_accuracy: 0.5810\n",
      "Epoch 60/100\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.7968 - accuracy: 0.6239 - val_loss: 0.8238 - val_accuracy: 0.6004\n",
      "Epoch 61/100\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.7912 - accuracy: 0.6098 - val_loss: 0.8542 - val_accuracy: 0.5745\n",
      "Epoch 62/100\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.7969 - accuracy: 0.6120 - val_loss: 0.8069 - val_accuracy: 0.6177\n",
      "Epoch 63/100\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.7906 - accuracy: 0.6299 - val_loss: 0.8810 - val_accuracy: 0.5486\n",
      "Epoch 64/100\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.7905 - accuracy: 0.6163 - val_loss: 0.8123 - val_accuracy: 0.6177\n",
      "Epoch 65/100\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.7792 - accuracy: 0.6288 - val_loss: 0.8257 - val_accuracy: 0.5961\n",
      "Epoch 66/100\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.7751 - accuracy: 0.6196 - val_loss: 0.8172 - val_accuracy: 0.6004\n",
      "Epoch 67/100\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.7640 - accuracy: 0.6364 - val_loss: 0.8527 - val_accuracy: 0.5961\n",
      "Epoch 68/100\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.7641 - accuracy: 0.6380 - val_loss: 0.8348 - val_accuracy: 0.5853\n",
      "Epoch 69/100\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.7679 - accuracy: 0.6364 - val_loss: 0.8063 - val_accuracy: 0.6199\n",
      "Epoch 70/100\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.7578 - accuracy: 0.6499 - val_loss: 0.8170 - val_accuracy: 0.6112\n",
      "Epoch 71/100\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.7642 - accuracy: 0.6385 - val_loss: 0.8172 - val_accuracy: 0.6069\n",
      "Epoch 72/100\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.7581 - accuracy: 0.6412 - val_loss: 0.7953 - val_accuracy: 0.6307\n",
      "Epoch 73/100\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.7502 - accuracy: 0.6407 - val_loss: 0.8002 - val_accuracy: 0.6134\n",
      "Epoch 74/100\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.7531 - accuracy: 0.6385 - val_loss: 0.8091 - val_accuracy: 0.5940\n",
      "Epoch 75/100\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.7394 - accuracy: 0.6531 - val_loss: 0.8055 - val_accuracy: 0.6263\n",
      "Epoch 76/100\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.7472 - accuracy: 0.6477 - val_loss: 0.8133 - val_accuracy: 0.6112\n",
      "Epoch 77/100\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.7481 - accuracy: 0.6542 - val_loss: 0.8013 - val_accuracy: 0.6004\n",
      "Epoch 78/100\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.7419 - accuracy: 0.6585 - val_loss: 0.8394 - val_accuracy: 0.5680\n",
      "Epoch 79/100\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.7356 - accuracy: 0.6477 - val_loss: 0.7988 - val_accuracy: 0.6156\n",
      "Epoch 80/100\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.7430 - accuracy: 0.6494 - val_loss: 0.7922 - val_accuracy: 0.6415\n",
      "Epoch 81/100\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.7366 - accuracy: 0.6412 - val_loss: 0.8075 - val_accuracy: 0.6069\n",
      "Epoch 82/100\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.7317 - accuracy: 0.6558 - val_loss: 0.8251 - val_accuracy: 0.6026\n",
      "Epoch 83/100\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.7269 - accuracy: 0.6488 - val_loss: 0.8037 - val_accuracy: 0.6112\n",
      "Epoch 84/100\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.7298 - accuracy: 0.6515 - val_loss: 0.8312 - val_accuracy: 0.5896\n",
      "Epoch 85/100\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.7388 - accuracy: 0.6510 - val_loss: 0.7993 - val_accuracy: 0.6004\n",
      "Epoch 86/100\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.7285 - accuracy: 0.6488 - val_loss: 0.8216 - val_accuracy: 0.5918\n",
      "Epoch 87/100\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.7201 - accuracy: 0.6650 - val_loss: 0.8096 - val_accuracy: 0.6156\n",
      "Epoch 88/100\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.7194 - accuracy: 0.6650 - val_loss: 0.7965 - val_accuracy: 0.6307\n",
      "Epoch 89/100\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.7240 - accuracy: 0.6618 - val_loss: 0.7966 - val_accuracy: 0.6177\n",
      "Epoch 90/100\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.7181 - accuracy: 0.6618 - val_loss: 0.8105 - val_accuracy: 0.6199\n",
      "Epoch 91/100\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.7184 - accuracy: 0.6602 - val_loss: 0.8074 - val_accuracy: 0.6177\n",
      "Epoch 92/100\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.7191 - accuracy: 0.6683 - val_loss: 0.8008 - val_accuracy: 0.6134\n",
      "Epoch 93/100\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.7030 - accuracy: 0.6797 - val_loss: 0.7911 - val_accuracy: 0.6393\n",
      "Epoch 94/100\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.7117 - accuracy: 0.6645 - val_loss: 0.7982 - val_accuracy: 0.6199\n",
      "Epoch 95/100\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.7038 - accuracy: 0.6715 - val_loss: 0.8272 - val_accuracy: 0.5940\n",
      "Epoch 96/100\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.7087 - accuracy: 0.6721 - val_loss: 0.8175 - val_accuracy: 0.6048\n",
      "Epoch 97/100\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.7204 - accuracy: 0.6688 - val_loss: 0.8085 - val_accuracy: 0.6134\n",
      "Epoch 98/100\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.7038 - accuracy: 0.6732 - val_loss: 0.8231 - val_accuracy: 0.6004\n",
      "Epoch 99/100\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.6984 - accuracy: 0.6845 - val_loss: 0.8151 - val_accuracy: 0.6091\n",
      "Epoch 100/100\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.6917 - accuracy: 0.6759 - val_loss: 0.8076 - val_accuracy: 0.6134\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2a91c8bfdf0>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 100\n",
    "\n",
    "model.fit(X_train, Y_train, validation_data=(X_test, Y_test), epochs=epochs, batch_size=64)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
