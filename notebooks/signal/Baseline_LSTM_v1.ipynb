{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Baseline model. 1 layer LSTM with a classification layer trained for 100 epochs'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Baseline model. 1 layer LSTM with a classification layer trained for 100 epochs\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../../data/processed/signalEUR_USD_Labelled_v1_processed.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Price</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Change %</th>\n",
       "      <th>diff_1</th>\n",
       "      <th>label</th>\n",
       "      <th>sma</th>\n",
       "      <th>ema</th>\n",
       "      <th>cma</th>\n",
       "      <th>macd</th>\n",
       "      <th>macd_s</th>\n",
       "      <th>macd_h</th>\n",
       "      <th>roc</th>\n",
       "      <th>rsi</th>\n",
       "      <th>Bollinger_up</th>\n",
       "      <th>Bollinger_down</th>\n",
       "      <th>cci</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1.3205</td>\n",
       "      <td>1.3194</td>\n",
       "      <td>1.3220</td>\n",
       "      <td>1.3180</td>\n",
       "      <td>0.07%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.320500</td>\n",
       "      <td>1.320500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>1.3186</td>\n",
       "      <td>1.3205</td>\n",
       "      <td>1.3302</td>\n",
       "      <td>1.3157</td>\n",
       "      <td>-0.14%</td>\n",
       "      <td>-0.0019</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.318956</td>\n",
       "      <td>1.319550</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-01-03</td>\n",
       "      <td>1.3048</td>\n",
       "      <td>1.3187</td>\n",
       "      <td>1.3192</td>\n",
       "      <td>1.3046</td>\n",
       "      <td>-1.05%</td>\n",
       "      <td>-0.0138</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.307931</td>\n",
       "      <td>1.314633</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-01-04</td>\n",
       "      <td>1.3069</td>\n",
       "      <td>1.3048</td>\n",
       "      <td>1.3091</td>\n",
       "      <td>1.2999</td>\n",
       "      <td>0.16%</td>\n",
       "      <td>0.0021</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.307136</td>\n",
       "      <td>1.312700</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.559663</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-01-07</td>\n",
       "      <td>1.3117</td>\n",
       "      <td>1.3072</td>\n",
       "      <td>1.3121</td>\n",
       "      <td>1.3018</td>\n",
       "      <td>0.37%</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.310649</td>\n",
       "      <td>1.312500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.329386</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date   Price    Open    High     Low Change %  diff_1  label  sma  \\\n",
       "0  2013-01-01  1.3205  1.3194  1.3220  1.3180    0.07%     NaN    NaN  NaN   \n",
       "1  2013-01-02  1.3186  1.3205  1.3302  1.3157   -0.14% -0.0019    0.0  NaN   \n",
       "2  2013-01-03  1.3048  1.3187  1.3192  1.3046   -1.05% -0.0138    1.0  NaN   \n",
       "3  2013-01-04  1.3069  1.3048  1.3091  1.2999    0.16%  0.0021    2.0  NaN   \n",
       "4  2013-01-07  1.3117  1.3072  1.3121  1.3018    0.37%  0.0048    2.0  NaN   \n",
       "\n",
       "        ema       cma  macd  macd_s  macd_h  roc        rsi  Bollinger_up  \\\n",
       "0  1.320500  1.320500   NaN     NaN     NaN  NaN        NaN           NaN   \n",
       "1  1.318956  1.319550   NaN     NaN     NaN  NaN   0.000000           NaN   \n",
       "2  1.307931  1.314633   NaN     NaN     NaN  NaN   0.000000           NaN   \n",
       "3  1.307136  1.312700   NaN     NaN     NaN  NaN  13.559663           NaN   \n",
       "4  1.310649  1.312500   NaN     NaN     NaN  NaN  36.329386           NaN   \n",
       "\n",
       "   Bollinger_down  cci  \n",
       "0             NaN  NaN  \n",
       "1             NaN  NaN  \n",
       "2             NaN  NaN  \n",
       "3             NaN  NaN  \n",
       "4             NaN  NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def prepare_data(df):\n",
    "    df[\"label_3days\"] = df[\"label\"].shift(-3)\n",
    "    df[\"label_5days\"] = df[\"label\"].shift(-5)\n",
    "    df = df.dropna(axis=0)\n",
    "    df = df.reset_index(drop=True)\n",
    "\n",
    "    time = [\"Date\"]\n",
    "    var = [\"Price\",  \"sma\", \"ema\", \"cma\", \"macd\",\t\"macd_s\", \n",
    "               \"macd_h\", \"roc\", \"rsi\",\t\"Bollinger_up\", \"Bollinger_down\", \"cci\"]\n",
    "    columns = []\n",
    "    for v in var:\n",
    "        columns.append(v)\n",
    "        columns.append(v + \"(t-2)\")\n",
    "        columns.append(v + \"(t-1)\")\n",
    "    \n",
    "    labels = [\"label\", \"label_3days\", \"label_5days\"]\n",
    "    features = df[time + columns + labels]\n",
    "\n",
    "    X = features.drop(labels= time + labels, axis=1)\n",
    "    print(X.head(5))\n",
    "    Y = features[[\"label\"]]\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "\n",
    "    onehot_encoder = OneHotEncoder()\n",
    "    Y = to_categorical(Y)\n",
    "    \n",
    "    return X, Y, features\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date(t-2)</th>\n",
       "      <th>Price(t-2)</th>\n",
       "      <th>Open(t-2)</th>\n",
       "      <th>High(t-2)</th>\n",
       "      <th>Low(t-2)</th>\n",
       "      <th>Change %(t-2)</th>\n",
       "      <th>diff_1(t-2)</th>\n",
       "      <th>label(t-2)</th>\n",
       "      <th>sma(t-2)</th>\n",
       "      <th>ema(t-2)</th>\n",
       "      <th>cma(t-2)</th>\n",
       "      <th>macd(t-2)</th>\n",
       "      <th>macd_s(t-2)</th>\n",
       "      <th>macd_h(t-2)</th>\n",
       "      <th>roc(t-2)</th>\n",
       "      <th>rsi(t-2)</th>\n",
       "      <th>Bollinger_up(t-2)</th>\n",
       "      <th>Bollinger_down(t-2)</th>\n",
       "      <th>cci(t-2)</th>\n",
       "      <th>label_3days(t-2)</th>\n",
       "      <th>label_5days(t-2)</th>\n",
       "      <th>Date(t-1)</th>\n",
       "      <th>Price(t-1)</th>\n",
       "      <th>Open(t-1)</th>\n",
       "      <th>High(t-1)</th>\n",
       "      <th>Low(t-1)</th>\n",
       "      <th>Change %(t-1)</th>\n",
       "      <th>diff_1(t-1)</th>\n",
       "      <th>label(t-1)</th>\n",
       "      <th>sma(t-1)</th>\n",
       "      <th>ema(t-1)</th>\n",
       "      <th>cma(t-1)</th>\n",
       "      <th>macd(t-1)</th>\n",
       "      <th>macd_s(t-1)</th>\n",
       "      <th>macd_h(t-1)</th>\n",
       "      <th>roc(t-1)</th>\n",
       "      <th>rsi(t-1)</th>\n",
       "      <th>Bollinger_up(t-1)</th>\n",
       "      <th>Bollinger_down(t-1)</th>\n",
       "      <th>cci(t-1)</th>\n",
       "      <th>label_3days(t-1)</th>\n",
       "      <th>label_5days(t-1)</th>\n",
       "      <th>Date</th>\n",
       "      <th>Price</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Change %</th>\n",
       "      <th>diff_1</th>\n",
       "      <th>label</th>\n",
       "      <th>sma</th>\n",
       "      <th>ema</th>\n",
       "      <th>cma</th>\n",
       "      <th>macd</th>\n",
       "      <th>macd_s</th>\n",
       "      <th>macd_h</th>\n",
       "      <th>roc</th>\n",
       "      <th>rsi</th>\n",
       "      <th>Bollinger_up</th>\n",
       "      <th>Bollinger_down</th>\n",
       "      <th>cci</th>\n",
       "      <th>label_3days</th>\n",
       "      <th>label_5days</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2013-02-15</td>\n",
       "      <td>1.3363</td>\n",
       "      <td>1.3363</td>\n",
       "      <td>1.3394</td>\n",
       "      <td>1.3306</td>\n",
       "      <td>0.01%</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.344735</td>\n",
       "      <td>1.336730</td>\n",
       "      <td>1.335315</td>\n",
       "      <td>0.002701</td>\n",
       "      <td>0.005461</td>\n",
       "      <td>-0.002760</td>\n",
       "      <td>-0.000150</td>\n",
       "      <td>39.939646</td>\n",
       "      <td>1.364281</td>\n",
       "      <td>1.325189</td>\n",
       "      <td>-62.849696</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2013-02-18</td>\n",
       "      <td>1.3352</td>\n",
       "      <td>1.3357</td>\n",
       "      <td>1.3377</td>\n",
       "      <td>1.3321</td>\n",
       "      <td>-0.08%</td>\n",
       "      <td>-0.0011</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.344925</td>\n",
       "      <td>1.335553</td>\n",
       "      <td>1.335311</td>\n",
       "      <td>0.001906</td>\n",
       "      <td>0.004750</td>\n",
       "      <td>-0.002844</td>\n",
       "      <td>-0.004102</td>\n",
       "      <td>38.588551</td>\n",
       "      <td>1.363994</td>\n",
       "      <td>1.325856</td>\n",
       "      <td>-68.561252</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2013-02-19</td>\n",
       "      <td>1.3388</td>\n",
       "      <td>1.3352</td>\n",
       "      <td>1.3397</td>\n",
       "      <td>1.3329</td>\n",
       "      <td>0.27%</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.345260</td>\n",
       "      <td>1.338051</td>\n",
       "      <td>1.335408</td>\n",
       "      <td>0.001549</td>\n",
       "      <td>0.004109</td>\n",
       "      <td>-0.002561</td>\n",
       "      <td>-0.004906</td>\n",
       "      <td>45.544851</td>\n",
       "      <td>1.363601</td>\n",
       "      <td>1.326919</td>\n",
       "      <td>-57.039491</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2013-02-18</td>\n",
       "      <td>1.3352</td>\n",
       "      <td>1.3357</td>\n",
       "      <td>1.3377</td>\n",
       "      <td>1.3321</td>\n",
       "      <td>-0.08%</td>\n",
       "      <td>-0.0011</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.344925</td>\n",
       "      <td>1.335553</td>\n",
       "      <td>1.335311</td>\n",
       "      <td>0.001906</td>\n",
       "      <td>0.004750</td>\n",
       "      <td>-0.002844</td>\n",
       "      <td>-0.004102</td>\n",
       "      <td>38.588551</td>\n",
       "      <td>1.363994</td>\n",
       "      <td>1.325856</td>\n",
       "      <td>-68.561252</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2013-02-19</td>\n",
       "      <td>1.3388</td>\n",
       "      <td>1.3352</td>\n",
       "      <td>1.3397</td>\n",
       "      <td>1.3329</td>\n",
       "      <td>0.27%</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.345260</td>\n",
       "      <td>1.338051</td>\n",
       "      <td>1.335408</td>\n",
       "      <td>0.001549</td>\n",
       "      <td>0.004109</td>\n",
       "      <td>-0.002561</td>\n",
       "      <td>-0.004906</td>\n",
       "      <td>45.544851</td>\n",
       "      <td>1.363601</td>\n",
       "      <td>1.326919</td>\n",
       "      <td>-57.039491</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2013-02-20</td>\n",
       "      <td>1.3281</td>\n",
       "      <td>1.3387</td>\n",
       "      <td>1.3434</td>\n",
       "      <td>1.3270</td>\n",
       "      <td>-0.80%</td>\n",
       "      <td>-0.0107</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.345075</td>\n",
       "      <td>1.330396</td>\n",
       "      <td>1.335211</td>\n",
       "      <td>0.000398</td>\n",
       "      <td>0.003367</td>\n",
       "      <td>-0.002969</td>\n",
       "      <td>-0.012785</td>\n",
       "      <td>32.802173</td>\n",
       "      <td>1.364052</td>\n",
       "      <td>1.326098</td>\n",
       "      <td>-90.131403</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2013-02-19</td>\n",
       "      <td>1.3388</td>\n",
       "      <td>1.3352</td>\n",
       "      <td>1.3397</td>\n",
       "      <td>1.3329</td>\n",
       "      <td>0.27%</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.345260</td>\n",
       "      <td>1.338051</td>\n",
       "      <td>1.335408</td>\n",
       "      <td>0.001549</td>\n",
       "      <td>0.004109</td>\n",
       "      <td>-0.002561</td>\n",
       "      <td>-0.004906</td>\n",
       "      <td>45.544851</td>\n",
       "      <td>1.363601</td>\n",
       "      <td>1.326919</td>\n",
       "      <td>-57.039491</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2013-02-20</td>\n",
       "      <td>1.3281</td>\n",
       "      <td>1.3387</td>\n",
       "      <td>1.3434</td>\n",
       "      <td>1.3270</td>\n",
       "      <td>-0.80%</td>\n",
       "      <td>-0.0107</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.345075</td>\n",
       "      <td>1.330396</td>\n",
       "      <td>1.335211</td>\n",
       "      <td>0.000398</td>\n",
       "      <td>0.003367</td>\n",
       "      <td>-0.002969</td>\n",
       "      <td>-0.012785</td>\n",
       "      <td>32.802173</td>\n",
       "      <td>1.364052</td>\n",
       "      <td>1.326098</td>\n",
       "      <td>-90.131403</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2013-02-21</td>\n",
       "      <td>1.3189</td>\n",
       "      <td>1.3283</td>\n",
       "      <td>1.3291</td>\n",
       "      <td>1.3161</td>\n",
       "      <td>-0.69%</td>\n",
       "      <td>-0.0092</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.344140</td>\n",
       "      <td>1.321553</td>\n",
       "      <td>1.334782</td>\n",
       "      <td>-0.001242</td>\n",
       "      <td>0.002445</td>\n",
       "      <td>-0.003688</td>\n",
       "      <td>-0.012873</td>\n",
       "      <td>25.675429</td>\n",
       "      <td>1.366251</td>\n",
       "      <td>1.322029</td>\n",
       "      <td>-149.263447</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2013-02-20</td>\n",
       "      <td>1.3281</td>\n",
       "      <td>1.3387</td>\n",
       "      <td>1.3434</td>\n",
       "      <td>1.3270</td>\n",
       "      <td>-0.80%</td>\n",
       "      <td>-0.0107</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.345075</td>\n",
       "      <td>1.330396</td>\n",
       "      <td>1.335211</td>\n",
       "      <td>0.000398</td>\n",
       "      <td>0.003367</td>\n",
       "      <td>-0.002969</td>\n",
       "      <td>-0.012785</td>\n",
       "      <td>32.802173</td>\n",
       "      <td>1.364052</td>\n",
       "      <td>1.326098</td>\n",
       "      <td>-90.131403</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2013-02-21</td>\n",
       "      <td>1.3189</td>\n",
       "      <td>1.3283</td>\n",
       "      <td>1.3291</td>\n",
       "      <td>1.3161</td>\n",
       "      <td>-0.69%</td>\n",
       "      <td>-0.0092</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.344140</td>\n",
       "      <td>1.321553</td>\n",
       "      <td>1.334782</td>\n",
       "      <td>-0.001242</td>\n",
       "      <td>0.002445</td>\n",
       "      <td>-0.003688</td>\n",
       "      <td>-0.012873</td>\n",
       "      <td>25.675429</td>\n",
       "      <td>1.366251</td>\n",
       "      <td>1.322029</td>\n",
       "      <td>-149.263447</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2013-02-22</td>\n",
       "      <td>1.3190</td>\n",
       "      <td>1.3190</td>\n",
       "      <td>1.3247</td>\n",
       "      <td>1.3146</td>\n",
       "      <td>0.01%</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.342780</td>\n",
       "      <td>1.319589</td>\n",
       "      <td>1.334377</td>\n",
       "      <td>-0.002505</td>\n",
       "      <td>0.001455</td>\n",
       "      <td>-0.003960</td>\n",
       "      <td>-0.012946</td>\n",
       "      <td>25.877405</td>\n",
       "      <td>1.367545</td>\n",
       "      <td>1.318015</td>\n",
       "      <td>-135.430243</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2013-02-21</td>\n",
       "      <td>1.3189</td>\n",
       "      <td>1.3283</td>\n",
       "      <td>1.3291</td>\n",
       "      <td>1.3161</td>\n",
       "      <td>-0.69%</td>\n",
       "      <td>-0.0092</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.344140</td>\n",
       "      <td>1.321553</td>\n",
       "      <td>1.334782</td>\n",
       "      <td>-0.001242</td>\n",
       "      <td>0.002445</td>\n",
       "      <td>-0.003688</td>\n",
       "      <td>-0.012873</td>\n",
       "      <td>25.675429</td>\n",
       "      <td>1.366251</td>\n",
       "      <td>1.322029</td>\n",
       "      <td>-149.263447</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2013-02-22</td>\n",
       "      <td>1.3190</td>\n",
       "      <td>1.3190</td>\n",
       "      <td>1.3247</td>\n",
       "      <td>1.3146</td>\n",
       "      <td>0.01%</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.342780</td>\n",
       "      <td>1.319589</td>\n",
       "      <td>1.334377</td>\n",
       "      <td>-0.002505</td>\n",
       "      <td>0.001455</td>\n",
       "      <td>-0.003960</td>\n",
       "      <td>-0.012946</td>\n",
       "      <td>25.877405</td>\n",
       "      <td>1.367545</td>\n",
       "      <td>1.318015</td>\n",
       "      <td>-135.430243</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2013-02-25</td>\n",
       "      <td>1.3062</td>\n",
       "      <td>1.3175</td>\n",
       "      <td>1.3319</td>\n",
       "      <td>1.3047</td>\n",
       "      <td>-0.97%</td>\n",
       "      <td>-0.0128</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.340810</td>\n",
       "      <td>1.309290</td>\n",
       "      <td>1.333673</td>\n",
       "      <td>-0.004487</td>\n",
       "      <td>0.000267</td>\n",
       "      <td>-0.004754</td>\n",
       "      <td>-0.021720</td>\n",
       "      <td>18.466037</td>\n",
       "      <td>1.370424</td>\n",
       "      <td>1.311196</td>\n",
       "      <td>-136.799244</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2339</th>\n",
       "      <td>2021-12-16</td>\n",
       "      <td>1.1328</td>\n",
       "      <td>1.1286</td>\n",
       "      <td>1.1361</td>\n",
       "      <td>1.1280</td>\n",
       "      <td>0.38%</td>\n",
       "      <td>0.0043</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.128465</td>\n",
       "      <td>1.131698</td>\n",
       "      <td>1.181217</td>\n",
       "      <td>-0.003936</td>\n",
       "      <td>-0.005225</td>\n",
       "      <td>0.001289</td>\n",
       "      <td>0.003188</td>\n",
       "      <td>55.445142</td>\n",
       "      <td>1.136545</td>\n",
       "      <td>1.120385</td>\n",
       "      <td>74.514054</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2021-12-17</td>\n",
       "      <td>1.1239</td>\n",
       "      <td>1.1330</td>\n",
       "      <td>1.1350</td>\n",
       "      <td>1.1235</td>\n",
       "      <td>-0.79%</td>\n",
       "      <td>-0.0089</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.128215</td>\n",
       "      <td>1.125699</td>\n",
       "      <td>1.181192</td>\n",
       "      <td>-0.004130</td>\n",
       "      <td>-0.005006</td>\n",
       "      <td>0.000876</td>\n",
       "      <td>-0.006365</td>\n",
       "      <td>39.869634</td>\n",
       "      <td>1.136544</td>\n",
       "      <td>1.119886</td>\n",
       "      <td>-18.249815</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2021-12-20</td>\n",
       "      <td>1.1275</td>\n",
       "      <td>1.1242</td>\n",
       "      <td>1.1305</td>\n",
       "      <td>1.1234</td>\n",
       "      <td>0.32%</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.128420</td>\n",
       "      <td>1.127084</td>\n",
       "      <td>1.181169</td>\n",
       "      <td>-0.003948</td>\n",
       "      <td>-0.004795</td>\n",
       "      <td>0.000847</td>\n",
       "      <td>-0.000709</td>\n",
       "      <td>46.839553</td>\n",
       "      <td>1.136446</td>\n",
       "      <td>1.120394</td>\n",
       "      <td>-27.330869</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2340</th>\n",
       "      <td>2021-12-17</td>\n",
       "      <td>1.1239</td>\n",
       "      <td>1.1330</td>\n",
       "      <td>1.1350</td>\n",
       "      <td>1.1235</td>\n",
       "      <td>-0.79%</td>\n",
       "      <td>-0.0089</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.128215</td>\n",
       "      <td>1.125699</td>\n",
       "      <td>1.181192</td>\n",
       "      <td>-0.004130</td>\n",
       "      <td>-0.005006</td>\n",
       "      <td>0.000876</td>\n",
       "      <td>-0.006365</td>\n",
       "      <td>39.869634</td>\n",
       "      <td>1.136544</td>\n",
       "      <td>1.119886</td>\n",
       "      <td>-18.249815</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2021-12-20</td>\n",
       "      <td>1.1275</td>\n",
       "      <td>1.1242</td>\n",
       "      <td>1.1305</td>\n",
       "      <td>1.1234</td>\n",
       "      <td>0.32%</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.128420</td>\n",
       "      <td>1.127084</td>\n",
       "      <td>1.181169</td>\n",
       "      <td>-0.003948</td>\n",
       "      <td>-0.004795</td>\n",
       "      <td>0.000847</td>\n",
       "      <td>-0.000709</td>\n",
       "      <td>46.839553</td>\n",
       "      <td>1.136446</td>\n",
       "      <td>1.120394</td>\n",
       "      <td>-27.330869</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2021-12-21</td>\n",
       "      <td>1.1283</td>\n",
       "      <td>1.1277</td>\n",
       "      <td>1.1303</td>\n",
       "      <td>1.1260</td>\n",
       "      <td>0.07%</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.128605</td>\n",
       "      <td>1.128019</td>\n",
       "      <td>1.181147</td>\n",
       "      <td>-0.003696</td>\n",
       "      <td>-0.004575</td>\n",
       "      <td>0.000879</td>\n",
       "      <td>0.002310</td>\n",
       "      <td>48.373952</td>\n",
       "      <td>1.136429</td>\n",
       "      <td>1.120781</td>\n",
       "      <td>-9.274996</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2341</th>\n",
       "      <td>2021-12-20</td>\n",
       "      <td>1.1275</td>\n",
       "      <td>1.1242</td>\n",
       "      <td>1.1305</td>\n",
       "      <td>1.1234</td>\n",
       "      <td>0.32%</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.128420</td>\n",
       "      <td>1.127084</td>\n",
       "      <td>1.181169</td>\n",
       "      <td>-0.003948</td>\n",
       "      <td>-0.004795</td>\n",
       "      <td>0.000847</td>\n",
       "      <td>-0.000709</td>\n",
       "      <td>46.839553</td>\n",
       "      <td>1.136446</td>\n",
       "      <td>1.120394</td>\n",
       "      <td>-27.330869</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2021-12-21</td>\n",
       "      <td>1.1283</td>\n",
       "      <td>1.1277</td>\n",
       "      <td>1.1303</td>\n",
       "      <td>1.1260</td>\n",
       "      <td>0.07%</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.128605</td>\n",
       "      <td>1.128019</td>\n",
       "      <td>1.181147</td>\n",
       "      <td>-0.003696</td>\n",
       "      <td>-0.004575</td>\n",
       "      <td>0.000879</td>\n",
       "      <td>0.002310</td>\n",
       "      <td>48.373952</td>\n",
       "      <td>1.136429</td>\n",
       "      <td>1.120781</td>\n",
       "      <td>-9.274996</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2021-12-22</td>\n",
       "      <td>1.1324</td>\n",
       "      <td>1.1279</td>\n",
       "      <td>1.1343</td>\n",
       "      <td>1.1264</td>\n",
       "      <td>0.36%</td>\n",
       "      <td>0.0041</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.129240</td>\n",
       "      <td>1.131389</td>\n",
       "      <td>1.181126</td>\n",
       "      <td>-0.003130</td>\n",
       "      <td>-0.004286</td>\n",
       "      <td>0.001156</td>\n",
       "      <td>0.003456</td>\n",
       "      <td>55.900932</td>\n",
       "      <td>1.136011</td>\n",
       "      <td>1.122469</td>\n",
       "      <td>47.075103</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2342</th>\n",
       "      <td>2021-12-21</td>\n",
       "      <td>1.1283</td>\n",
       "      <td>1.1277</td>\n",
       "      <td>1.1303</td>\n",
       "      <td>1.1260</td>\n",
       "      <td>0.07%</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.128605</td>\n",
       "      <td>1.128019</td>\n",
       "      <td>1.181147</td>\n",
       "      <td>-0.003696</td>\n",
       "      <td>-0.004575</td>\n",
       "      <td>0.000879</td>\n",
       "      <td>0.002310</td>\n",
       "      <td>48.373952</td>\n",
       "      <td>1.136429</td>\n",
       "      <td>1.120781</td>\n",
       "      <td>-9.274996</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2021-12-22</td>\n",
       "      <td>1.1324</td>\n",
       "      <td>1.1279</td>\n",
       "      <td>1.1343</td>\n",
       "      <td>1.1264</td>\n",
       "      <td>0.36%</td>\n",
       "      <td>0.0041</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.129240</td>\n",
       "      <td>1.131389</td>\n",
       "      <td>1.181126</td>\n",
       "      <td>-0.003130</td>\n",
       "      <td>-0.004286</td>\n",
       "      <td>0.001156</td>\n",
       "      <td>0.003456</td>\n",
       "      <td>55.900932</td>\n",
       "      <td>1.136011</td>\n",
       "      <td>1.122469</td>\n",
       "      <td>47.075103</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2021-12-23</td>\n",
       "      <td>1.1328</td>\n",
       "      <td>1.1325</td>\n",
       "      <td>1.1343</td>\n",
       "      <td>1.1289</td>\n",
       "      <td>0.04%</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.129850</td>\n",
       "      <td>1.132474</td>\n",
       "      <td>1.181105</td>\n",
       "      <td>-0.002618</td>\n",
       "      <td>-0.003952</td>\n",
       "      <td>0.001334</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56.613022</td>\n",
       "      <td>1.135439</td>\n",
       "      <td>1.124261</td>\n",
       "      <td>77.106303</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2343</th>\n",
       "      <td>2021-12-22</td>\n",
       "      <td>1.1324</td>\n",
       "      <td>1.1279</td>\n",
       "      <td>1.1343</td>\n",
       "      <td>1.1264</td>\n",
       "      <td>0.36%</td>\n",
       "      <td>0.0041</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.129240</td>\n",
       "      <td>1.131389</td>\n",
       "      <td>1.181126</td>\n",
       "      <td>-0.003130</td>\n",
       "      <td>-0.004286</td>\n",
       "      <td>0.001156</td>\n",
       "      <td>0.003456</td>\n",
       "      <td>55.900932</td>\n",
       "      <td>1.136011</td>\n",
       "      <td>1.122469</td>\n",
       "      <td>47.075103</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2021-12-23</td>\n",
       "      <td>1.1328</td>\n",
       "      <td>1.1325</td>\n",
       "      <td>1.1343</td>\n",
       "      <td>1.1289</td>\n",
       "      <td>0.04%</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.129850</td>\n",
       "      <td>1.132474</td>\n",
       "      <td>1.181105</td>\n",
       "      <td>-0.002618</td>\n",
       "      <td>-0.003952</td>\n",
       "      <td>0.001334</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56.613022</td>\n",
       "      <td>1.135439</td>\n",
       "      <td>1.124261</td>\n",
       "      <td>77.106303</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2021-12-24</td>\n",
       "      <td>1.1317</td>\n",
       "      <td>1.1330</td>\n",
       "      <td>1.1344</td>\n",
       "      <td>1.1303</td>\n",
       "      <td>-0.10%</td>\n",
       "      <td>-0.0011</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.129850</td>\n",
       "      <td>1.131879</td>\n",
       "      <td>1.181084</td>\n",
       "      <td>-0.002276</td>\n",
       "      <td>-0.003617</td>\n",
       "      <td>0.001341</td>\n",
       "      <td>0.006940</td>\n",
       "      <td>53.853702</td>\n",
       "      <td>1.135439</td>\n",
       "      <td>1.124261</td>\n",
       "      <td>73.581941</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2309 rows Ã— 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Date(t-2)  Price(t-2)  Open(t-2)  High(t-2)  Low(t-2) Change %(t-2)  \\\n",
       "35    2013-02-15      1.3363     1.3363     1.3394    1.3306         0.01%   \n",
       "36    2013-02-18      1.3352     1.3357     1.3377    1.3321        -0.08%   \n",
       "37    2013-02-19      1.3388     1.3352     1.3397    1.3329         0.27%   \n",
       "38    2013-02-20      1.3281     1.3387     1.3434    1.3270        -0.80%   \n",
       "39    2013-02-21      1.3189     1.3283     1.3291    1.3161        -0.69%   \n",
       "...          ...         ...        ...        ...       ...           ...   \n",
       "2339  2021-12-16      1.1328     1.1286     1.1361    1.1280         0.38%   \n",
       "2340  2021-12-17      1.1239     1.1330     1.1350    1.1235        -0.79%   \n",
       "2341  2021-12-20      1.1275     1.1242     1.1305    1.1234         0.32%   \n",
       "2342  2021-12-21      1.1283     1.1277     1.1303    1.1260         0.07%   \n",
       "2343  2021-12-22      1.1324     1.1279     1.1343    1.1264         0.36%   \n",
       "\n",
       "      diff_1(t-2)  label(t-2)  sma(t-2)  ema(t-2)  cma(t-2)  macd(t-2)  \\\n",
       "35         0.0002         0.0  1.344735  1.336730  1.335315   0.002701   \n",
       "36        -0.0011         0.0  1.344925  1.335553  1.335311   0.001906   \n",
       "37         0.0036         2.0  1.345260  1.338051  1.335408   0.001549   \n",
       "38        -0.0107         1.0  1.345075  1.330396  1.335211   0.000398   \n",
       "39        -0.0092         1.0  1.344140  1.321553  1.334782  -0.001242   \n",
       "...           ...         ...       ...       ...       ...        ...   \n",
       "2339       0.0043         2.0  1.128465  1.131698  1.181217  -0.003936   \n",
       "2340      -0.0089         1.0  1.128215  1.125699  1.181192  -0.004130   \n",
       "2341       0.0036         2.0  1.128420  1.127084  1.181169  -0.003948   \n",
       "2342       0.0008         0.0  1.128605  1.128019  1.181147  -0.003696   \n",
       "2343       0.0041         2.0  1.129240  1.131389  1.181126  -0.003130   \n",
       "\n",
       "      macd_s(t-2)  macd_h(t-2)  roc(t-2)   rsi(t-2)  Bollinger_up(t-2)  \\\n",
       "35       0.005461    -0.002760 -0.000150  39.939646           1.364281   \n",
       "36       0.004750    -0.002844 -0.004102  38.588551           1.363994   \n",
       "37       0.004109    -0.002561 -0.004906  45.544851           1.363601   \n",
       "38       0.003367    -0.002969 -0.012785  32.802173           1.364052   \n",
       "39       0.002445    -0.003688 -0.012873  25.675429           1.366251   \n",
       "...           ...          ...       ...        ...                ...   \n",
       "2339    -0.005225     0.001289  0.003188  55.445142           1.136545   \n",
       "2340    -0.005006     0.000876 -0.006365  39.869634           1.136544   \n",
       "2341    -0.004795     0.000847 -0.000709  46.839553           1.136446   \n",
       "2342    -0.004575     0.000879  0.002310  48.373952           1.136429   \n",
       "2343    -0.004286     0.001156  0.003456  55.900932           1.136011   \n",
       "\n",
       "      Bollinger_down(t-2)    cci(t-2)  label_3days(t-2)  label_5days(t-2)  \\\n",
       "35               1.325189  -62.849696               1.0               0.0   \n",
       "36               1.325856  -68.561252               1.0               1.0   \n",
       "37               1.326919  -57.039491               0.0               0.0   \n",
       "38               1.326098  -90.131403               1.0               2.0   \n",
       "39               1.322029 -149.263447               0.0               1.0   \n",
       "...                   ...         ...               ...               ...   \n",
       "2339             1.120385   74.514054               0.0               0.0   \n",
       "2340             1.119886  -18.249815               2.0               0.0   \n",
       "2341             1.120394  -27.330869               0.0               0.0   \n",
       "2342             1.120781   -9.274996               0.0               0.0   \n",
       "2343             1.122469   47.075103               0.0               2.0   \n",
       "\n",
       "       Date(t-1)  Price(t-1)  Open(t-1)  High(t-1)  Low(t-1) Change %(t-1)  \\\n",
       "35    2013-02-18      1.3352     1.3357     1.3377    1.3321        -0.08%   \n",
       "36    2013-02-19      1.3388     1.3352     1.3397    1.3329         0.27%   \n",
       "37    2013-02-20      1.3281     1.3387     1.3434    1.3270        -0.80%   \n",
       "38    2013-02-21      1.3189     1.3283     1.3291    1.3161        -0.69%   \n",
       "39    2013-02-22      1.3190     1.3190     1.3247    1.3146         0.01%   \n",
       "...          ...         ...        ...        ...       ...           ...   \n",
       "2339  2021-12-17      1.1239     1.1330     1.1350    1.1235        -0.79%   \n",
       "2340  2021-12-20      1.1275     1.1242     1.1305    1.1234         0.32%   \n",
       "2341  2021-12-21      1.1283     1.1277     1.1303    1.1260         0.07%   \n",
       "2342  2021-12-22      1.1324     1.1279     1.1343    1.1264         0.36%   \n",
       "2343  2021-12-23      1.1328     1.1325     1.1343    1.1289         0.04%   \n",
       "\n",
       "      diff_1(t-1)  label(t-1)  sma(t-1)  ema(t-1)  cma(t-1)  macd(t-1)  \\\n",
       "35        -0.0011         0.0  1.344925  1.335553  1.335311   0.001906   \n",
       "36         0.0036         2.0  1.345260  1.338051  1.335408   0.001549   \n",
       "37        -0.0107         1.0  1.345075  1.330396  1.335211   0.000398   \n",
       "38        -0.0092         1.0  1.344140  1.321553  1.334782  -0.001242   \n",
       "39         0.0001         0.0  1.342780  1.319589  1.334377  -0.002505   \n",
       "...           ...         ...       ...       ...       ...        ...   \n",
       "2339      -0.0089         1.0  1.128215  1.125699  1.181192  -0.004130   \n",
       "2340       0.0036         2.0  1.128420  1.127084  1.181169  -0.003948   \n",
       "2341       0.0008         0.0  1.128605  1.128019  1.181147  -0.003696   \n",
       "2342       0.0041         2.0  1.129240  1.131389  1.181126  -0.003130   \n",
       "2343       0.0004         0.0  1.129850  1.132474  1.181105  -0.002618   \n",
       "\n",
       "      macd_s(t-1)  macd_h(t-1)  roc(t-1)   rsi(t-1)  Bollinger_up(t-1)  \\\n",
       "35       0.004750    -0.002844 -0.004102  38.588551           1.363994   \n",
       "36       0.004109    -0.002561 -0.004906  45.544851           1.363601   \n",
       "37       0.003367    -0.002969 -0.012785  32.802173           1.364052   \n",
       "38       0.002445    -0.003688 -0.012873  25.675429           1.366251   \n",
       "39       0.001455    -0.003960 -0.012946  25.877405           1.367545   \n",
       "...           ...          ...       ...        ...                ...   \n",
       "2339    -0.005006     0.000876 -0.006365  39.869634           1.136544   \n",
       "2340    -0.004795     0.000847 -0.000709  46.839553           1.136446   \n",
       "2341    -0.004575     0.000879  0.002310  48.373952           1.136429   \n",
       "2342    -0.004286     0.001156  0.003456  55.900932           1.136011   \n",
       "2343    -0.003952     0.001334  0.000000  56.613022           1.135439   \n",
       "\n",
       "      Bollinger_down(t-1)    cci(t-1)  label_3days(t-1)  label_5days(t-1)  \\\n",
       "35               1.325856  -68.561252               1.0               1.0   \n",
       "36               1.326919  -57.039491               0.0               0.0   \n",
       "37               1.326098  -90.131403               1.0               2.0   \n",
       "38               1.322029 -149.263447               0.0               1.0   \n",
       "39               1.318015 -135.430243               2.0               1.0   \n",
       "...                   ...         ...               ...               ...   \n",
       "2339             1.119886  -18.249815               2.0               0.0   \n",
       "2340             1.120394  -27.330869               0.0               0.0   \n",
       "2341             1.120781   -9.274996               0.0               0.0   \n",
       "2342             1.122469   47.075103               0.0               2.0   \n",
       "2343             1.124261   77.106303               0.0               1.0   \n",
       "\n",
       "            Date   Price    Open    High     Low Change %  diff_1  label  \\\n",
       "35    2013-02-19  1.3388  1.3352  1.3397  1.3329    0.27%  0.0036    2.0   \n",
       "36    2013-02-20  1.3281  1.3387  1.3434  1.3270   -0.80% -0.0107    1.0   \n",
       "37    2013-02-21  1.3189  1.3283  1.3291  1.3161   -0.69% -0.0092    1.0   \n",
       "38    2013-02-22  1.3190  1.3190  1.3247  1.3146    0.01%  0.0001    0.0   \n",
       "39    2013-02-25  1.3062  1.3175  1.3319  1.3047   -0.97% -0.0128    1.0   \n",
       "...          ...     ...     ...     ...     ...      ...     ...    ...   \n",
       "2339  2021-12-20  1.1275  1.1242  1.1305  1.1234    0.32%  0.0036    2.0   \n",
       "2340  2021-12-21  1.1283  1.1277  1.1303  1.1260    0.07%  0.0008    0.0   \n",
       "2341  2021-12-22  1.1324  1.1279  1.1343  1.1264    0.36%  0.0041    2.0   \n",
       "2342  2021-12-23  1.1328  1.1325  1.1343  1.1289    0.04%  0.0004    0.0   \n",
       "2343  2021-12-24  1.1317  1.1330  1.1344  1.1303   -0.10% -0.0011    0.0   \n",
       "\n",
       "           sma       ema       cma      macd    macd_s    macd_h       roc  \\\n",
       "35    1.345260  1.338051  1.335408  0.001549  0.004109 -0.002561 -0.004906   \n",
       "36    1.345075  1.330396  1.335211  0.000398  0.003367 -0.002969 -0.012785   \n",
       "37    1.344140  1.321553  1.334782 -0.001242  0.002445 -0.003688 -0.012873   \n",
       "38    1.342780  1.319589  1.334377 -0.002505  0.001455 -0.003960 -0.012946   \n",
       "39    1.340810  1.309290  1.333673 -0.004487  0.000267 -0.004754 -0.021720   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "2339  1.128420  1.127084  1.181169 -0.003948 -0.004795  0.000847 -0.000709   \n",
       "2340  1.128605  1.128019  1.181147 -0.003696 -0.004575  0.000879  0.002310   \n",
       "2341  1.129240  1.131389  1.181126 -0.003130 -0.004286  0.001156  0.003456   \n",
       "2342  1.129850  1.132474  1.181105 -0.002618 -0.003952  0.001334  0.000000   \n",
       "2343  1.129850  1.131879  1.181084 -0.002276 -0.003617  0.001341  0.006940   \n",
       "\n",
       "            rsi  Bollinger_up  Bollinger_down         cci  label_3days  \\\n",
       "35    45.544851      1.363601        1.326919  -57.039491          0.0   \n",
       "36    32.802173      1.364052        1.326098  -90.131403          1.0   \n",
       "37    25.675429      1.366251        1.322029 -149.263447          0.0   \n",
       "38    25.877405      1.367545        1.318015 -135.430243          2.0   \n",
       "39    18.466037      1.370424        1.311196 -136.799244          1.0   \n",
       "...         ...           ...             ...         ...          ...   \n",
       "2339  46.839553      1.136446        1.120394  -27.330869          0.0   \n",
       "2340  48.373952      1.136429        1.120781   -9.274996          0.0   \n",
       "2341  55.900932      1.136011        1.122469   47.075103          0.0   \n",
       "2342  56.613022      1.135439        1.124261   77.106303          0.0   \n",
       "2343  53.853702      1.135439        1.124261   73.581941          2.0   \n",
       "\n",
       "      label_5days  \n",
       "35            0.0  \n",
       "36            2.0  \n",
       "37            1.0  \n",
       "38            1.0  \n",
       "39            0.0  \n",
       "...           ...  \n",
       "2339          0.0  \n",
       "2340          0.0  \n",
       "2341          2.0  \n",
       "2342          1.0  \n",
       "2343          2.0  \n",
       "\n",
       "[2309 rows x 63 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pandas import concat\n",
    "\n",
    "def window(df):\n",
    "    \"\"\"Given time series data, window it such that we can get (t-2), (t-1) and (t)\"\"\"\n",
    "    n_var = df.shape[1]\n",
    "    cols, names = list(), list()\n",
    "\n",
    "    n_prev = 2\n",
    "    for i in range(n_prev, -1, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        if i > 0:\n",
    "            names += [(f\"{j}(t-{i})\") for j in list(df.columns)]\n",
    "        else:\n",
    "            names += [(f\"{j}\") for j in list(df.columns)]\n",
    "    agg = concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    agg.dropna(inplace=True)\n",
    "    return agg\n",
    "agg = window(df)\n",
    "pd.set_option('display.max_columns', None)\n",
    "agg\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Price  Price(t-2)  Price(t-1)       sma  sma(t-2)  sma(t-1)       ema  \\\n",
      "0  1.3388      1.3363      1.3352  1.345260  1.344735  1.344925  1.338051   \n",
      "1  1.3281      1.3352      1.3388  1.345075  1.344925  1.345260  1.330396   \n",
      "2  1.3189      1.3388      1.3281  1.344140  1.345260  1.345075  1.321553   \n",
      "3  1.3190      1.3281      1.3189  1.342780  1.345075  1.344140  1.319589   \n",
      "4  1.3062      1.3189      1.3190  1.340810  1.344140  1.342780  1.309290   \n",
      "\n",
      "   ema(t-2)  ema(t-1)       cma  cma(t-2)  cma(t-1)      macd  macd(t-2)  \\\n",
      "0  1.336730  1.335553  1.335408  1.335315  1.335311  0.001549   0.002701   \n",
      "1  1.335553  1.338051  1.335211  1.335311  1.335408  0.000398   0.001906   \n",
      "2  1.338051  1.330396  1.334782  1.335408  1.335211 -0.001242   0.001549   \n",
      "3  1.330396  1.321553  1.334377  1.335211  1.334782 -0.002505   0.000398   \n",
      "4  1.321553  1.319589  1.333673  1.334782  1.334377 -0.004487  -0.001242   \n",
      "\n",
      "   macd(t-1)    macd_s  macd_s(t-2)  macd_s(t-1)    macd_h  macd_h(t-2)  \\\n",
      "0   0.001906  0.004109     0.005461     0.004750 -0.002561    -0.002760   \n",
      "1   0.001549  0.003367     0.004750     0.004109 -0.002969    -0.002844   \n",
      "2   0.000398  0.002445     0.004109     0.003367 -0.003688    -0.002561   \n",
      "3  -0.001242  0.001455     0.003367     0.002445 -0.003960    -0.002969   \n",
      "4  -0.002505  0.000267     0.002445     0.001455 -0.004754    -0.003688   \n",
      "\n",
      "   macd_h(t-1)       roc  roc(t-2)  roc(t-1)        rsi   rsi(t-2)   rsi(t-1)  \\\n",
      "0    -0.002844 -0.004906 -0.000150 -0.004102  45.544851  39.939646  38.588551   \n",
      "1    -0.002561 -0.012785 -0.004102 -0.004906  32.802173  38.588551  45.544851   \n",
      "2    -0.002969 -0.012873 -0.004906 -0.012785  25.675429  45.544851  32.802173   \n",
      "3    -0.003688 -0.012946 -0.012785 -0.012873  25.877405  32.802173  25.675429   \n",
      "4    -0.003960 -0.021720 -0.012873 -0.012946  18.466037  25.675429  25.877405   \n",
      "\n",
      "   Bollinger_up  Bollinger_up(t-2)  Bollinger_up(t-1)  Bollinger_down  \\\n",
      "0      1.363601           1.364281           1.363994        1.326919   \n",
      "1      1.364052           1.363994           1.363601        1.326098   \n",
      "2      1.366251           1.363601           1.364052        1.322029   \n",
      "3      1.367545           1.364052           1.366251        1.318015   \n",
      "4      1.370424           1.366251           1.367545        1.311196   \n",
      "\n",
      "   Bollinger_down(t-2)  Bollinger_down(t-1)         cci    cci(t-2)  \\\n",
      "0             1.325189             1.325856  -57.039491  -62.849696   \n",
      "1             1.325856             1.326919  -90.131403  -68.561252   \n",
      "2             1.326919             1.326098 -149.263447  -57.039491   \n",
      "3             1.326098             1.322029 -135.430243  -90.131403   \n",
      "4             1.322029             1.318015 -136.799244 -149.263447   \n",
      "\n",
      "     cci(t-1)  \n",
      "0  -68.561252  \n",
      "1  -57.039491  \n",
      "2  -90.131403  \n",
      "3 -149.263447  \n",
      "4 -135.430243  \n",
      "(1843, 36) (461, 36)\n",
      "(1843, 3) (461, 3)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, Y, features = prepare_data(window(df))\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=420)\n",
    "print(X_train.shape, X_test.shape)\n",
    "print(Y_train.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_2 (LSTM)               (None, 100)               40800     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 3)                 303       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 41,103\n",
      "Trainable params: 41,103\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Input\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.losses import CategoricalCrossentropy\n",
    "\n",
    "h_dim = 100\n",
    "num_classes = 3\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=h_dim, input_shape=(X_train.shape[1], 1)))\n",
    "model.add(Dense(num_classes))\n",
    "model.compile(loss=CategoricalCrossentropy(from_logits=True), optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "29/29 [==============================] - 2s 28ms/step - loss: 1.1008 - accuracy: 0.3370 - val_loss: 1.0972 - val_accuracy: 0.3297\n",
      "Epoch 2/100\n",
      "29/29 [==============================] - 1s 19ms/step - loss: 1.0957 - accuracy: 0.3440 - val_loss: 1.0936 - val_accuracy: 0.3536\n",
      "Epoch 3/100\n",
      "29/29 [==============================] - 1s 20ms/step - loss: 1.0940 - accuracy: 0.3630 - val_loss: 1.0917 - val_accuracy: 0.3666\n",
      "Epoch 4/100\n",
      "29/29 [==============================] - 1s 20ms/step - loss: 1.0896 - accuracy: 0.3543 - val_loss: 1.0916 - val_accuracy: 0.3774\n",
      "Epoch 5/100\n",
      "29/29 [==============================] - 1s 19ms/step - loss: 1.0835 - accuracy: 0.3852 - val_loss: 1.1287 - val_accuracy: 0.3492\n",
      "Epoch 6/100\n",
      "29/29 [==============================] - 1s 19ms/step - loss: 1.0832 - accuracy: 0.4010 - val_loss: 1.0901 - val_accuracy: 0.3514\n",
      "Epoch 7/100\n",
      "29/29 [==============================] - 1s 20ms/step - loss: 1.0795 - accuracy: 0.4010 - val_loss: 1.0840 - val_accuracy: 0.3796\n",
      "Epoch 8/100\n",
      "29/29 [==============================] - 1s 20ms/step - loss: 1.0760 - accuracy: 0.4194 - val_loss: 1.0813 - val_accuracy: 0.4208\n",
      "Epoch 9/100\n",
      "29/29 [==============================] - 1s 19ms/step - loss: 1.0700 - accuracy: 0.4151 - val_loss: 1.0788 - val_accuracy: 0.4121\n",
      "Epoch 10/100\n",
      "29/29 [==============================] - 1s 20ms/step - loss: 1.0600 - accuracy: 0.4249 - val_loss: 1.0721 - val_accuracy: 0.4360\n",
      "Epoch 11/100\n",
      "29/29 [==============================] - 1s 20ms/step - loss: 1.0586 - accuracy: 0.4482 - val_loss: 1.0646 - val_accuracy: 0.4512\n",
      "Epoch 12/100\n",
      "29/29 [==============================] - 1s 20ms/step - loss: 1.0485 - accuracy: 0.4590 - val_loss: 1.0602 - val_accuracy: 0.4360\n",
      "Epoch 13/100\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 1.0421 - accuracy: 0.4840 - val_loss: 1.0361 - val_accuracy: 0.4685\n",
      "Epoch 14/100\n",
      "29/29 [==============================] - 1s 19ms/step - loss: 1.0224 - accuracy: 0.4704 - val_loss: 1.0295 - val_accuracy: 0.4707\n",
      "Epoch 15/100\n",
      "29/29 [==============================] - 1s 19ms/step - loss: 1.0138 - accuracy: 0.4948 - val_loss: 1.0118 - val_accuracy: 0.5141\n",
      "Epoch 16/100\n",
      "29/29 [==============================] - 1s 19ms/step - loss: 0.9854 - accuracy: 0.5133 - val_loss: 1.0013 - val_accuracy: 0.4881\n",
      "Epoch 17/100\n",
      "29/29 [==============================] - 1s 19ms/step - loss: 0.9620 - accuracy: 0.5388 - val_loss: 0.9583 - val_accuracy: 0.5640\n",
      "Epoch 18/100\n",
      "29/29 [==============================] - 1s 18ms/step - loss: 0.9504 - accuracy: 0.5458 - val_loss: 0.9507 - val_accuracy: 0.5488\n",
      "Epoch 19/100\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 0.9244 - accuracy: 0.5773 - val_loss: 0.9398 - val_accuracy: 0.5466\n",
      "Epoch 20/100\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 0.9011 - accuracy: 0.5833 - val_loss: 0.9017 - val_accuracy: 0.6009\n",
      "Epoch 21/100\n",
      "29/29 [==============================] - 1s 20ms/step - loss: 0.8730 - accuracy: 0.5893 - val_loss: 1.0106 - val_accuracy: 0.4794\n",
      "Epoch 22/100\n",
      "29/29 [==============================] - 1s 20ms/step - loss: 0.8557 - accuracy: 0.6245 - val_loss: 0.8789 - val_accuracy: 0.5944\n",
      "Epoch 23/100\n",
      "29/29 [==============================] - 1s 20ms/step - loss: 0.8430 - accuracy: 0.6055 - val_loss: 0.8705 - val_accuracy: 0.6074\n",
      "Epoch 24/100\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 0.8039 - accuracy: 0.6565 - val_loss: 0.8955 - val_accuracy: 0.5271\n",
      "Epoch 25/100\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 0.7831 - accuracy: 0.6484 - val_loss: 0.8014 - val_accuracy: 0.6399\n",
      "Epoch 26/100\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 0.7370 - accuracy: 0.6603 - val_loss: 0.8223 - val_accuracy: 0.6247\n",
      "Epoch 27/100\n",
      "29/29 [==============================] - 1s 20ms/step - loss: 0.7010 - accuracy: 0.6940 - val_loss: 0.7271 - val_accuracy: 0.6963\n",
      "Epoch 28/100\n",
      "29/29 [==============================] - 1s 20ms/step - loss: 0.6300 - accuracy: 0.7292 - val_loss: 0.6815 - val_accuracy: 0.6811\n",
      "Epoch 29/100\n",
      "29/29 [==============================] - 1s 20ms/step - loss: 0.6185 - accuracy: 0.7108 - val_loss: 0.6530 - val_accuracy: 0.7115\n",
      "Epoch 30/100\n",
      "29/29 [==============================] - 1s 20ms/step - loss: 0.5920 - accuracy: 0.7347 - val_loss: 0.6913 - val_accuracy: 0.6746\n",
      "Epoch 31/100\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 0.5657 - accuracy: 0.7553 - val_loss: 0.6829 - val_accuracy: 0.6638\n",
      "Epoch 32/100\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 0.5535 - accuracy: 0.7537 - val_loss: 0.6145 - val_accuracy: 0.7245\n",
      "Epoch 33/100\n",
      "29/29 [==============================] - 1s 20ms/step - loss: 0.5357 - accuracy: 0.7634 - val_loss: 0.5952 - val_accuracy: 0.7180\n",
      "Epoch 34/100\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 0.4996 - accuracy: 0.7813 - val_loss: 0.5904 - val_accuracy: 0.7375\n",
      "Epoch 35/100\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 0.4741 - accuracy: 0.7916 - val_loss: 0.5302 - val_accuracy: 0.7744\n",
      "Epoch 36/100\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 0.4649 - accuracy: 0.7965 - val_loss: 0.5591 - val_accuracy: 0.7657\n",
      "Epoch 37/100\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 0.4357 - accuracy: 0.8237 - val_loss: 0.4927 - val_accuracy: 0.7809\n",
      "Epoch 38/100\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 0.3936 - accuracy: 0.8437 - val_loss: 0.4406 - val_accuracy: 0.7983\n",
      "Epoch 39/100\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 0.3812 - accuracy: 0.8410 - val_loss: 0.4216 - val_accuracy: 0.8026\n",
      "Epoch 40/100\n",
      "29/29 [==============================] - 1s 20ms/step - loss: 0.3692 - accuracy: 0.8530 - val_loss: 0.4490 - val_accuracy: 0.8048\n",
      "Epoch 41/100\n",
      "29/29 [==============================] - 1s 20ms/step - loss: 0.3484 - accuracy: 0.8535 - val_loss: 0.5257 - val_accuracy: 0.7636\n",
      "Epoch 42/100\n",
      "29/29 [==============================] - 1s 20ms/step - loss: 0.3801 - accuracy: 0.8454 - val_loss: 0.4374 - val_accuracy: 0.8069\n",
      "Epoch 43/100\n",
      "29/29 [==============================] - 1s 19ms/step - loss: 0.3433 - accuracy: 0.8578 - val_loss: 0.4047 - val_accuracy: 0.8243\n",
      "Epoch 44/100\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 0.3171 - accuracy: 0.8790 - val_loss: 0.4689 - val_accuracy: 0.8004\n",
      "Epoch 45/100\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 0.3166 - accuracy: 0.8676 - val_loss: 0.4428 - val_accuracy: 0.8026\n",
      "Epoch 46/100\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 0.3103 - accuracy: 0.8741 - val_loss: 0.4266 - val_accuracy: 0.8113\n",
      "Epoch 47/100\n",
      "29/29 [==============================] - 1s 20ms/step - loss: 0.3242 - accuracy: 0.8627 - val_loss: 0.3973 - val_accuracy: 0.8330\n",
      "Epoch 48/100\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 0.2963 - accuracy: 0.8828 - val_loss: 0.4370 - val_accuracy: 0.8069\n",
      "Epoch 49/100\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 0.2895 - accuracy: 0.8871 - val_loss: 0.4008 - val_accuracy: 0.8243\n",
      "Epoch 50/100\n",
      "29/29 [==============================] - 1s 20ms/step - loss: 0.2707 - accuracy: 0.8871 - val_loss: 0.3897 - val_accuracy: 0.8265\n",
      "Epoch 51/100\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 0.2775 - accuracy: 0.8817 - val_loss: 0.3957 - val_accuracy: 0.8373\n",
      "Epoch 52/100\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 0.2701 - accuracy: 0.8893 - val_loss: 0.4054 - val_accuracy: 0.8113\n",
      "Epoch 53/100\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 0.2972 - accuracy: 0.8714 - val_loss: 0.3811 - val_accuracy: 0.8330\n",
      "Epoch 54/100\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 0.2571 - accuracy: 0.8974 - val_loss: 0.5407 - val_accuracy: 0.7722\n",
      "Epoch 55/100\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 0.2852 - accuracy: 0.8833 - val_loss: 0.3870 - val_accuracy: 0.8200\n",
      "Epoch 56/100\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 0.2531 - accuracy: 0.8942 - val_loss: 0.3529 - val_accuracy: 0.8460\n",
      "Epoch 57/100\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 0.2740 - accuracy: 0.8828 - val_loss: 0.5335 - val_accuracy: 0.7766\n",
      "Epoch 58/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 1s 20ms/step - loss: 0.2854 - accuracy: 0.8844 - val_loss: 0.3349 - val_accuracy: 0.8482\n",
      "Epoch 59/100\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 0.2375 - accuracy: 0.9012 - val_loss: 0.3578 - val_accuracy: 0.8460\n",
      "Epoch 60/100\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 0.2254 - accuracy: 0.9148 - val_loss: 0.3343 - val_accuracy: 0.8568\n",
      "Epoch 61/100\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 0.2198 - accuracy: 0.9078 - val_loss: 0.3308 - val_accuracy: 0.8612\n",
      "Epoch 62/100\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 0.2025 - accuracy: 0.9246 - val_loss: 0.3325 - val_accuracy: 0.8503\n",
      "Epoch 63/100\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 0.2675 - accuracy: 0.8855 - val_loss: 0.3653 - val_accuracy: 0.8330\n",
      "Epoch 64/100\n",
      "29/29 [==============================] - 1s 20ms/step - loss: 0.2179 - accuracy: 0.9029 - val_loss: 0.3776 - val_accuracy: 0.8460\n",
      "Epoch 65/100\n",
      "29/29 [==============================] - 1s 20ms/step - loss: 0.1930 - accuracy: 0.9267 - val_loss: 0.3356 - val_accuracy: 0.8633\n",
      "Epoch 66/100\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 0.2203 - accuracy: 0.9061 - val_loss: 0.3842 - val_accuracy: 0.8351\n",
      "Epoch 67/100\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 0.2140 - accuracy: 0.9116 - val_loss: 0.3410 - val_accuracy: 0.8460\n",
      "Epoch 68/100\n",
      "29/29 [==============================] - 1s 20ms/step - loss: 0.1986 - accuracy: 0.9197 - val_loss: 0.3585 - val_accuracy: 0.8547\n",
      "Epoch 69/100\n",
      "29/29 [==============================] - 1s 20ms/step - loss: 0.2120 - accuracy: 0.9126 - val_loss: 0.3805 - val_accuracy: 0.8395\n",
      "Epoch 70/100\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 0.2043 - accuracy: 0.9132 - val_loss: 0.4238 - val_accuracy: 0.8286\n",
      "Epoch 71/100\n",
      "29/29 [==============================] - 1s 20ms/step - loss: 0.2437 - accuracy: 0.8991 - val_loss: 0.3983 - val_accuracy: 0.8156\n",
      "Epoch 72/100\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 0.1805 - accuracy: 0.9343 - val_loss: 0.3490 - val_accuracy: 0.8547\n",
      "Epoch 73/100\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 0.2188 - accuracy: 0.9040 - val_loss: 0.3830 - val_accuracy: 0.8416\n",
      "Epoch 74/100\n",
      "29/29 [==============================] - 1s 20ms/step - loss: 0.1915 - accuracy: 0.9273 - val_loss: 0.4108 - val_accuracy: 0.8330\n",
      "Epoch 75/100\n",
      "29/29 [==============================] - 1s 20ms/step - loss: 0.1622 - accuracy: 0.9343 - val_loss: 0.3816 - val_accuracy: 0.8416\n",
      "Epoch 76/100\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 0.1535 - accuracy: 0.9430 - val_loss: 0.2914 - val_accuracy: 0.8742\n",
      "Epoch 77/100\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 0.1621 - accuracy: 0.9349 - val_loss: 0.4259 - val_accuracy: 0.8286\n",
      "Epoch 78/100\n",
      "29/29 [==============================] - 1s 27ms/step - loss: 0.1784 - accuracy: 0.9262 - val_loss: 0.3896 - val_accuracy: 0.8525\n",
      "Epoch 79/100\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 0.1860 - accuracy: 0.9235 - val_loss: 0.3639 - val_accuracy: 0.8482\n",
      "Epoch 80/100\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 0.1503 - accuracy: 0.9447 - val_loss: 0.4680 - val_accuracy: 0.8156\n",
      "Epoch 81/100\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 0.1797 - accuracy: 0.9251 - val_loss: 0.3793 - val_accuracy: 0.8460\n",
      "Epoch 82/100\n",
      "29/29 [==============================] - 1s 20ms/step - loss: 0.1473 - accuracy: 0.9436 - val_loss: 0.3580 - val_accuracy: 0.8416\n",
      "Epoch 83/100\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 0.1603 - accuracy: 0.9381 - val_loss: 0.3242 - val_accuracy: 0.8590\n",
      "Epoch 84/100\n",
      "29/29 [==============================] - 1s 20ms/step - loss: 0.1467 - accuracy: 0.9403 - val_loss: 0.3094 - val_accuracy: 0.8677\n",
      "Epoch 85/100\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 0.1430 - accuracy: 0.9441 - val_loss: 0.3445 - val_accuracy: 0.8633\n",
      "Epoch 86/100\n",
      "29/29 [==============================] - 1s 20ms/step - loss: 0.1562 - accuracy: 0.9381 - val_loss: 0.3566 - val_accuracy: 0.8590\n",
      "Epoch 87/100\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 0.1329 - accuracy: 0.9495 - val_loss: 0.3295 - val_accuracy: 0.8547\n",
      "Epoch 88/100\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 0.1330 - accuracy: 0.9474 - val_loss: 0.3441 - val_accuracy: 0.8590\n",
      "Epoch 89/100\n",
      "29/29 [==============================] - 1s 20ms/step - loss: 0.1333 - accuracy: 0.9457 - val_loss: 0.3079 - val_accuracy: 0.8677\n",
      "Epoch 90/100\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 0.1238 - accuracy: 0.9593 - val_loss: 0.3179 - val_accuracy: 0.8720\n",
      "Epoch 91/100\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 0.1681 - accuracy: 0.9273 - val_loss: 0.4080 - val_accuracy: 0.8373\n",
      "Epoch 92/100\n",
      "29/29 [==============================] - 1s 20ms/step - loss: 0.1510 - accuracy: 0.9419 - val_loss: 0.3048 - val_accuracy: 0.8677\n",
      "Epoch 93/100\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 0.1205 - accuracy: 0.9598 - val_loss: 0.3001 - val_accuracy: 0.8698\n",
      "Epoch 94/100\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 0.1336 - accuracy: 0.9485 - val_loss: 0.3744 - val_accuracy: 0.8655\n",
      "Epoch 95/100\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 0.1300 - accuracy: 0.9506 - val_loss: 0.3386 - val_accuracy: 0.8698\n",
      "Epoch 96/100\n",
      "29/29 [==============================] - 1s 20ms/step - loss: 0.1369 - accuracy: 0.9468 - val_loss: 0.4097 - val_accuracy: 0.8330\n",
      "Epoch 97/100\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 0.1588 - accuracy: 0.9322 - val_loss: 0.3620 - val_accuracy: 0.8633\n",
      "Epoch 98/100\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 0.1167 - accuracy: 0.9555 - val_loss: 0.3176 - val_accuracy: 0.8742\n",
      "Epoch 99/100\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 0.1008 - accuracy: 0.9685 - val_loss: 0.3920 - val_accuracy: 0.8568\n",
      "Epoch 100/100\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 0.0960 - accuracy: 0.9642 - val_loss: 0.3626 - val_accuracy: 0.8633\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1cd98c633d0>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 100\n",
    "\n",
    "model.fit(X_train, Y_train, validation_data=(X_test, Y_test), epochs=epochs, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Without price as a factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.75711290e+00,  1.74688028e+00,  1.85073459e+00, ...,\n",
       "        -5.82267337e-01, -6.48549048e-01, -7.15253591e-01],\n",
       "       [ 1.74482298e+00,  1.78712648e+00,  1.84866607e+00, ...,\n",
       "        -9.65166121e-01, -7.14635687e-01, -5.81952273e-01],\n",
       "       [ 1.78504452e+00,  1.66750584e+00,  1.83821161e+00, ...,\n",
       "        -1.64936920e+00, -5.81320962e-01, -9.64810006e-01],\n",
       "       ...,\n",
       "       [-5.66798082e-01, -5.95224900e-01, -5.71009894e-01, ...,\n",
       "        -3.10471530e-01, -1.79884284e-03, -1.28458797e-01],\n",
       "       [-5.95846969e-01, -5.63922301e-01, -5.73302048e-01, ...,\n",
       "         9.39908017e-01, -1.27781876e-01, -3.10185606e-01],\n",
       "       [-5.64563552e-01, -5.15850452e-01, -5.76097357e-01, ...,\n",
       "        -1.33441060e-01, -3.09526962e-01,  9.40059888e-01]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = features.drop(labels= [\"Date\"] + [\"label\", \"label_3days\", \"label_5days\"] + [\"Price\"], axis=1)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1843, 35) (461, 35)\n",
      "(1843, 3) (461, 3)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=420)\n",
    "print(X_train.shape, X_test.shape)\n",
    "print(Y_train.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_3 (LSTM)               (None, 100)               40800     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 3)                 303       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 41,103\n",
      "Trainable params: 41,103\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(units=h_dim, input_shape=(X_train.shape[1], 1)))\n",
    "model.add(Dense(num_classes))\n",
    "model.compile(loss=CategoricalCrossentropy(from_logits=True), optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "29/29 [==============================] - 2s 27ms/step - loss: 1.0996 - accuracy: 0.3435 - val_loss: 1.0978 - val_accuracy: 0.3341\n",
      "Epoch 2/100\n",
      "29/29 [==============================] - 1s 19ms/step - loss: 1.0965 - accuracy: 0.3397 - val_loss: 1.0961 - val_accuracy: 0.3275\n",
      "Epoch 3/100\n",
      "29/29 [==============================] - 1s 19ms/step - loss: 1.0943 - accuracy: 0.3576 - val_loss: 1.0927 - val_accuracy: 0.3449\n",
      "Epoch 4/100\n",
      "29/29 [==============================] - 1s 19ms/step - loss: 1.0906 - accuracy: 0.3570 - val_loss: 1.0894 - val_accuracy: 0.3818\n",
      "Epoch 5/100\n",
      "29/29 [==============================] - 1s 19ms/step - loss: 1.0869 - accuracy: 0.3874 - val_loss: 1.0890 - val_accuracy: 0.3623\n",
      "Epoch 6/100\n",
      "29/29 [==============================] - 1s 19ms/step - loss: 1.0833 - accuracy: 0.3928 - val_loss: 1.0843 - val_accuracy: 0.3948\n",
      "Epoch 7/100\n",
      "29/29 [==============================] - 1s 19ms/step - loss: 1.0792 - accuracy: 0.4059 - val_loss: 1.0787 - val_accuracy: 0.4121\n",
      "Epoch 8/100\n",
      "29/29 [==============================] - 1s 19ms/step - loss: 1.0746 - accuracy: 0.4037 - val_loss: 1.0774 - val_accuracy: 0.4295\n",
      "Epoch 9/100\n",
      "29/29 [==============================] - 1s 18ms/step - loss: 1.0786 - accuracy: 0.4140 - val_loss: 1.0733 - val_accuracy: 0.4360\n",
      "Epoch 10/100\n",
      "29/29 [==============================] - 1s 20ms/step - loss: 1.0735 - accuracy: 0.4053 - val_loss: 1.0775 - val_accuracy: 0.4447\n",
      "Epoch 11/100\n",
      "29/29 [==============================] - 1s 19ms/step - loss: 1.0716 - accuracy: 0.4270 - val_loss: 1.0776 - val_accuracy: 0.3991\n",
      "Epoch 12/100\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 1.0627 - accuracy: 0.4205 - val_loss: 1.0696 - val_accuracy: 0.4295\n",
      "Epoch 13/100\n",
      "29/29 [==============================] - 1s 19ms/step - loss: 1.0550 - accuracy: 0.4352 - val_loss: 1.0592 - val_accuracy: 0.4534\n",
      "Epoch 14/100\n",
      "29/29 [==============================] - 1s 19ms/step - loss: 1.0486 - accuracy: 0.4536 - val_loss: 1.0712 - val_accuracy: 0.4338\n",
      "Epoch 15/100\n",
      "29/29 [==============================] - 1s 19ms/step - loss: 1.0389 - accuracy: 0.4802 - val_loss: 1.0387 - val_accuracy: 0.4620\n",
      "Epoch 16/100\n",
      "29/29 [==============================] - 1s 20ms/step - loss: 1.0150 - accuracy: 0.5046 - val_loss: 1.0140 - val_accuracy: 0.4989\n",
      "Epoch 17/100\n",
      "29/29 [==============================] - 1s 19ms/step - loss: 0.9954 - accuracy: 0.5133 - val_loss: 0.9909 - val_accuracy: 0.5184\n",
      "Epoch 18/100\n",
      "29/29 [==============================] - 1s 19ms/step - loss: 0.9644 - accuracy: 0.5377 - val_loss: 0.9709 - val_accuracy: 0.5358\n",
      "Epoch 19/100\n",
      "29/29 [==============================] - 1s 20ms/step - loss: 0.9446 - accuracy: 0.5491 - val_loss: 0.9533 - val_accuracy: 0.5315\n",
      "Epoch 20/100\n",
      "29/29 [==============================] - 1s 19ms/step - loss: 0.9177 - accuracy: 0.5692 - val_loss: 0.9198 - val_accuracy: 0.5835\n",
      "Epoch 21/100\n",
      "29/29 [==============================] - 1s 20ms/step - loss: 0.8927 - accuracy: 0.5887 - val_loss: 0.8964 - val_accuracy: 0.5640\n",
      "Epoch 22/100\n",
      "29/29 [==============================] - 1s 20ms/step - loss: 0.8638 - accuracy: 0.6044 - val_loss: 0.9022 - val_accuracy: 0.5748\n",
      "Epoch 23/100\n",
      "29/29 [==============================] - 1s 20ms/step - loss: 0.8512 - accuracy: 0.6202 - val_loss: 0.8896 - val_accuracy: 0.5748\n",
      "Epoch 24/100\n",
      "29/29 [==============================] - 1s 20ms/step - loss: 0.7798 - accuracy: 0.6533 - val_loss: 0.7788 - val_accuracy: 0.6529\n",
      "Epoch 25/100\n",
      "29/29 [==============================] - 1s 20ms/step - loss: 0.7064 - accuracy: 0.6934 - val_loss: 0.7647 - val_accuracy: 0.6377\n",
      "Epoch 26/100\n",
      "29/29 [==============================] - 1s 20ms/step - loss: 0.6783 - accuracy: 0.6907 - val_loss: 0.7136 - val_accuracy: 0.6920\n",
      "Epoch 27/100\n",
      "29/29 [==============================] - 1s 19ms/step - loss: 0.6381 - accuracy: 0.7146 - val_loss: 0.6990 - val_accuracy: 0.6898\n",
      "Epoch 28/100\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 0.6204 - accuracy: 0.7352 - val_loss: 0.7028 - val_accuracy: 0.6790\n",
      "Epoch 29/100\n",
      "29/29 [==============================] - 1s 20ms/step - loss: 0.5980 - accuracy: 0.7461 - val_loss: 0.6916 - val_accuracy: 0.6963\n",
      "Epoch 30/100\n",
      "29/29 [==============================] - 1s 19ms/step - loss: 0.5515 - accuracy: 0.7699 - val_loss: 0.6279 - val_accuracy: 0.7375\n",
      "Epoch 31/100\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 0.5070 - accuracy: 0.7889 - val_loss: 0.6040 - val_accuracy: 0.7289\n",
      "Epoch 32/100\n",
      "29/29 [==============================] - 1s 20ms/step - loss: 0.5128 - accuracy: 0.7727 - val_loss: 0.5847 - val_accuracy: 0.7397\n",
      "Epoch 33/100\n",
      "29/29 [==============================] - 1s 20ms/step - loss: 0.4639 - accuracy: 0.8030 - val_loss: 0.4938 - val_accuracy: 0.8113\n",
      "Epoch 34/100\n",
      "29/29 [==============================] - 1s 19ms/step - loss: 0.4521 - accuracy: 0.8063 - val_loss: 0.5606 - val_accuracy: 0.7505\n",
      "Epoch 35/100\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 0.4179 - accuracy: 0.8296 - val_loss: 0.4728 - val_accuracy: 0.7722\n",
      "Epoch 36/100\n",
      "29/29 [==============================] - 1s 20ms/step - loss: 0.4069 - accuracy: 0.8269 - val_loss: 0.4421 - val_accuracy: 0.8156\n",
      "Epoch 37/100\n",
      "29/29 [==============================] - 1s 20ms/step - loss: 0.3767 - accuracy: 0.8497 - val_loss: 0.5952 - val_accuracy: 0.7484\n",
      "Epoch 38/100\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 0.3869 - accuracy: 0.8269 - val_loss: 0.4634 - val_accuracy: 0.7852\n",
      "Epoch 39/100\n",
      "29/29 [==============================] - 1s 20ms/step - loss: 0.3749 - accuracy: 0.8334 - val_loss: 0.4531 - val_accuracy: 0.8091\n",
      "Epoch 40/100\n",
      "29/29 [==============================] - 1s 20ms/step - loss: 0.3431 - accuracy: 0.8606 - val_loss: 0.4263 - val_accuracy: 0.8069\n",
      "Epoch 41/100\n",
      "29/29 [==============================] - 1s 20ms/step - loss: 0.3290 - accuracy: 0.8671 - val_loss: 0.4434 - val_accuracy: 0.7961\n",
      "Epoch 42/100\n",
      "29/29 [==============================] - 1s 20ms/step - loss: 0.3600 - accuracy: 0.8426 - val_loss: 0.3802 - val_accuracy: 0.8503\n",
      "Epoch 43/100\n",
      "29/29 [==============================] - 1s 20ms/step - loss: 0.3185 - accuracy: 0.8676 - val_loss: 0.4173 - val_accuracy: 0.8265\n",
      "Epoch 44/100\n",
      "29/29 [==============================] - 1s 20ms/step - loss: 0.3260 - accuracy: 0.8698 - val_loss: 0.4590 - val_accuracy: 0.7896\n",
      "Epoch 45/100\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 0.3028 - accuracy: 0.8768 - val_loss: 0.4559 - val_accuracy: 0.8004\n",
      "Epoch 46/100\n",
      "29/29 [==============================] - 1s 20ms/step - loss: 0.3032 - accuracy: 0.8839 - val_loss: 0.3837 - val_accuracy: 0.8069\n",
      "Epoch 47/100\n",
      "29/29 [==============================] - 1s 20ms/step - loss: 0.3028 - accuracy: 0.8741 - val_loss: 0.3862 - val_accuracy: 0.8330\n",
      "Epoch 48/100\n",
      "29/29 [==============================] - 1s 20ms/step - loss: 0.3179 - accuracy: 0.8584 - val_loss: 0.4126 - val_accuracy: 0.8134\n",
      "Epoch 49/100\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 0.2830 - accuracy: 0.8839 - val_loss: 0.3613 - val_accuracy: 0.8373\n",
      "Epoch 50/100\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 0.2651 - accuracy: 0.8920 - val_loss: 0.3750 - val_accuracy: 0.8351\n",
      "Epoch 51/100\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 0.2643 - accuracy: 0.8877 - val_loss: 0.3642 - val_accuracy: 0.8438\n",
      "Epoch 52/100\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 0.2726 - accuracy: 0.8920 - val_loss: 0.3480 - val_accuracy: 0.8351\n",
      "Epoch 53/100\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 0.2880 - accuracy: 0.8779 - val_loss: 0.3855 - val_accuracy: 0.8351\n",
      "Epoch 54/100\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 0.2785 - accuracy: 0.8839 - val_loss: 0.3699 - val_accuracy: 0.8330\n",
      "Epoch 55/100\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 0.2384 - accuracy: 0.9050 - val_loss: 0.3094 - val_accuracy: 0.8698\n",
      "Epoch 56/100\n",
      "29/29 [==============================] - 1s 19ms/step - loss: 0.2753 - accuracy: 0.8747 - val_loss: 0.3518 - val_accuracy: 0.8503\n",
      "Epoch 57/100\n",
      "29/29 [==============================] - 1s 19ms/step - loss: 0.2458 - accuracy: 0.8964 - val_loss: 0.3479 - val_accuracy: 0.8568\n",
      "Epoch 58/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 1s 19ms/step - loss: 0.2165 - accuracy: 0.9170 - val_loss: 0.3485 - val_accuracy: 0.8351\n",
      "Epoch 59/100\n",
      "29/29 [==============================] - 1s 20ms/step - loss: 0.2329 - accuracy: 0.9045 - val_loss: 0.3267 - val_accuracy: 0.8503\n",
      "Epoch 60/100\n",
      "29/29 [==============================] - 1s 20ms/step - loss: 0.2388 - accuracy: 0.9007 - val_loss: 0.4558 - val_accuracy: 0.8156\n",
      "Epoch 61/100\n",
      "29/29 [==============================] - 1s 20ms/step - loss: 0.2826 - accuracy: 0.8812 - val_loss: 0.3798 - val_accuracy: 0.8286\n",
      "Epoch 62/100\n",
      "29/29 [==============================] - 1s 20ms/step - loss: 0.2039 - accuracy: 0.9186 - val_loss: 0.3523 - val_accuracy: 0.8655\n",
      "Epoch 63/100\n",
      "29/29 [==============================] - 1s 20ms/step - loss: 0.2170 - accuracy: 0.9105 - val_loss: 0.3232 - val_accuracy: 0.8547\n",
      "Epoch 64/100\n",
      "29/29 [==============================] - 1s 20ms/step - loss: 0.2288 - accuracy: 0.9002 - val_loss: 0.3886 - val_accuracy: 0.8330\n",
      "Epoch 65/100\n",
      "29/29 [==============================] - 1s 20ms/step - loss: 0.2247 - accuracy: 0.9045 - val_loss: 0.4043 - val_accuracy: 0.8200\n",
      "Epoch 66/100\n",
      "29/29 [==============================] - 1s 19ms/step - loss: 0.2250 - accuracy: 0.9094 - val_loss: 0.3318 - val_accuracy: 0.8525\n",
      "Epoch 67/100\n",
      "29/29 [==============================] - 1s 19ms/step - loss: 0.2238 - accuracy: 0.9061 - val_loss: 0.3684 - val_accuracy: 0.8395\n",
      "Epoch 68/100\n",
      "29/29 [==============================] - 1s 20ms/step - loss: 0.2346 - accuracy: 0.9034 - val_loss: 0.4286 - val_accuracy: 0.8200\n",
      "Epoch 69/100\n",
      "29/29 [==============================] - 1s 20ms/step - loss: 0.2231 - accuracy: 0.9029 - val_loss: 0.3329 - val_accuracy: 0.8525\n",
      "Epoch 70/100\n",
      "29/29 [==============================] - 1s 20ms/step - loss: 0.1931 - accuracy: 0.9267 - val_loss: 0.3214 - val_accuracy: 0.8742\n",
      "Epoch 71/100\n",
      "29/29 [==============================] - 1s 20ms/step - loss: 0.1883 - accuracy: 0.9311 - val_loss: 0.3708 - val_accuracy: 0.8460\n",
      "Epoch 72/100\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 0.2256 - accuracy: 0.9099 - val_loss: 0.3868 - val_accuracy: 0.8330\n",
      "Epoch 73/100\n",
      "29/29 [==============================] - 1s 20ms/step - loss: 0.1890 - accuracy: 0.9278 - val_loss: 0.4142 - val_accuracy: 0.8460\n",
      "Epoch 74/100\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 0.2434 - accuracy: 0.9045 - val_loss: 0.4718 - val_accuracy: 0.8091\n",
      "Epoch 75/100\n",
      "29/29 [==============================] - 1s 20ms/step - loss: 0.2092 - accuracy: 0.9170 - val_loss: 0.3077 - val_accuracy: 0.8698\n",
      "Epoch 76/100\n",
      "29/29 [==============================] - 1s 19ms/step - loss: 0.1806 - accuracy: 0.9300 - val_loss: 0.3603 - val_accuracy: 0.8568\n",
      "Epoch 77/100\n",
      "29/29 [==============================] - 1s 18ms/step - loss: 0.2103 - accuracy: 0.9072 - val_loss: 0.3496 - val_accuracy: 0.8547\n",
      "Epoch 78/100\n",
      "29/29 [==============================] - 1s 19ms/step - loss: 0.1553 - accuracy: 0.9436 - val_loss: 0.2892 - val_accuracy: 0.8742\n",
      "Epoch 79/100\n",
      "29/29 [==============================] - 1s 20ms/step - loss: 0.1697 - accuracy: 0.9316 - val_loss: 0.4009 - val_accuracy: 0.8395\n",
      "Epoch 80/100\n",
      "29/29 [==============================] - 1s 20ms/step - loss: 0.1758 - accuracy: 0.9251 - val_loss: 0.3812 - val_accuracy: 0.8330\n",
      "Epoch 81/100\n",
      "29/29 [==============================] - 1s 20ms/step - loss: 0.1840 - accuracy: 0.9213 - val_loss: 0.3971 - val_accuracy: 0.8286\n",
      "Epoch 82/100\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 0.1565 - accuracy: 0.9436 - val_loss: 0.2907 - val_accuracy: 0.8742\n",
      "Epoch 83/100\n",
      "29/29 [==============================] - 1s 20ms/step - loss: 0.1604 - accuracy: 0.9316 - val_loss: 0.4878 - val_accuracy: 0.8113\n",
      "Epoch 84/100\n",
      "29/29 [==============================] - 1s 19ms/step - loss: 0.1684 - accuracy: 0.9305 - val_loss: 0.4177 - val_accuracy: 0.8373\n",
      "Epoch 85/100\n",
      "29/29 [==============================] - 1s 20ms/step - loss: 0.2143 - accuracy: 0.9083 - val_loss: 0.3743 - val_accuracy: 0.8525\n",
      "Epoch 86/100\n",
      "29/29 [==============================] - 1s 20ms/step - loss: 0.1639 - accuracy: 0.9349 - val_loss: 0.3204 - val_accuracy: 0.8720\n",
      "Epoch 87/100\n",
      "29/29 [==============================] - 1s 19ms/step - loss: 0.1507 - accuracy: 0.9398 - val_loss: 0.2931 - val_accuracy: 0.8698\n",
      "Epoch 88/100\n",
      "29/29 [==============================] - 1s 20ms/step - loss: 0.1370 - accuracy: 0.9512 - val_loss: 0.3711 - val_accuracy: 0.8395\n",
      "Epoch 89/100\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 0.1457 - accuracy: 0.9381 - val_loss: 0.2961 - val_accuracy: 0.8764\n",
      "Epoch 90/100\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 0.1208 - accuracy: 0.9598 - val_loss: 0.2979 - val_accuracy: 0.8764\n",
      "Epoch 91/100\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 0.1496 - accuracy: 0.9360 - val_loss: 0.3048 - val_accuracy: 0.8677\n",
      "Epoch 92/100\n",
      "29/29 [==============================] - 1s 19ms/step - loss: 0.1537 - accuracy: 0.9376 - val_loss: 0.4283 - val_accuracy: 0.8351\n",
      "Epoch 93/100\n",
      "29/29 [==============================] - 1s 19ms/step - loss: 0.1760 - accuracy: 0.9262 - val_loss: 0.3465 - val_accuracy: 0.8525\n",
      "Epoch 94/100\n",
      "29/29 [==============================] - 1s 20ms/step - loss: 0.1185 - accuracy: 0.9577 - val_loss: 0.3428 - val_accuracy: 0.8590\n",
      "Epoch 95/100\n",
      "29/29 [==============================] - 1s 20ms/step - loss: 0.1556 - accuracy: 0.9376 - val_loss: 0.3281 - val_accuracy: 0.8698\n",
      "Epoch 96/100\n",
      "29/29 [==============================] - 1s 20ms/step - loss: 0.1300 - accuracy: 0.9485 - val_loss: 0.3564 - val_accuracy: 0.8503\n",
      "Epoch 97/100\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 0.1275 - accuracy: 0.9512 - val_loss: 0.4211 - val_accuracy: 0.8330\n",
      "Epoch 98/100\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 0.1364 - accuracy: 0.9485 - val_loss: 0.3411 - val_accuracy: 0.8460\n",
      "Epoch 99/100\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 0.1171 - accuracy: 0.9544 - val_loss: 0.3215 - val_accuracy: 0.8764\n",
      "Epoch 100/100\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 0.1548 - accuracy: 0.9409 - val_loss: 0.3924 - val_accuracy: 0.8590\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1cd98c31100>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 100\n",
    "\n",
    "model.fit(X_train, Y_train, validation_data=(X_test, Y_test), epochs=epochs, batch_size=64)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
